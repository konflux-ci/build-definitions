---
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: oci-copy-oci-ta
  annotations:
    tekton.dev/pipelines.minVersion: 0.12.1
    tekton.dev/tags: image-build, konflux
  labels:
    app.kubernetes.io/version: "0.1"
    build.appstudio.redhat.com/build_type: oci-artifact
spec:
  description: Given a file in the user's source directory, copy content from
    arbitrary urls into the OCI registry.
  params:
    - name: AWS_SECRET_NAME
      description: 'Name of a secret which will be made available to the build
        to construct Authorization headers for requests to Amazon S3 using
        v2 auth https://docs.aws.amazon.com/AmazonS3/latest/userguide/RESTAuthentication.html.
        If specified, this will take precedence over BEARER_TOKEN_SECRET_NAME.
        The secret must contain two keys: `aws_access_key_id` and `aws_secret_access_key`.
        In the future, this will be reimplemented to use v4 auth: https://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-auth-using-authorization-header.html.'
      type: string
      default: does-not-exist
    - name: BEARER_TOKEN_SECRET_NAME
      description: Name of a secret which will be made available to the build
        as an Authorization header. Note, the token will be sent to all servers
        found in the oci-copy.yaml file. If you do not wish to send the token
        to all servers, different taskruns and therefore different oci artifacts
        must be used.
      type: string
      default: does-not-exist
    - name: IMAGE
      description: Reference of the image we will push
      type: string
    - name: OCI_COPY_FILE
      description: Path to the oci copy file.
      type: string
      default: ./oci-copy.yaml
    - name: SOURCE_ARTIFACT
      description: The Trusted Artifact URI pointing to the artifact with
        the application source code.
      type: string
  results:
    - name: IMAGE_DIGEST
      description: Digest of the artifact just pushed
    - name: IMAGE_REF
      description: Image reference of the built image
    - name: IMAGE_URL
      description: Repository where the artifact was pushed
    - name: SBOM_BLOB_URL
      description: Link to the SBOM blob pushed to the registry.
  volumes:
    - name: varlibcontainers
      emptyDir: {}
    - name: workdir
      emptyDir: {}
  stepTemplate:
    env:
      - name: IMAGE
        value: $(params.IMAGE)
      - name: OCI_COPY_FILE
        value: $(params.OCI_COPY_FILE)
    volumeMounts:
      - mountPath: /var/workdir
        name: workdir
  steps:
    - name: use-trusted-artifact
      image: quay.io/redhat-appstudio/build-trusted-artifacts:latest@sha256:e0e457b6af10e44ff6b90208a9e69adc863a865e1c062c4cb84bf3846037d74d
      args:
        - use
        - $(params.SOURCE_ARTIFACT)=/var/workdir/source
    - name: prepare
      image: quay.io/konflux-ci/yq:latest@sha256:4ce1f9431020387eb6c33a28a46e079b0c28b97f916243d150e70a09e41ce6b4
      workingDir: /var/workdir
      script: |
        #!/bin/bash
        set -eu
        set -o pipefail

        oci_copy_file_path="$(pwd)/source/$OCI_COPY_FILE"

        mkdir -p "/var/workdir/vars/"

        for entry in $(cat $oci_copy_file_path | yq '.artifacts[] | @json | @base64'); do
          entry=$(echo $entry | base64 -d)
          source=$(echo $entry | yq .source)
          filename=$(echo $entry | yq .filename)
          artifact_type=$(echo $entry | yq .type)
          artifact_digest=$(echo $entry | yq .sha256sum)

          {
            echo "declare OCI_SOURCE=${source}"
            echo "declare OCI_FILENAME=${filename}"
            echo "declare OCI_ARTIFACT_TYPE=${artifact_type}"
            echo "declare OCI_ARTIFACT_DIGEST=${artifact_digest}"
          } >"/var/workdir/vars/$filename"

          echo "Wrote /var/workdir/vars/$filename with contents:"
          cat "/var/workdir/vars/$filename"
        done
    - name: oci-copy
      image: quay.io/konflux-ci/oras:latest@sha256:0fdcb8ad0528042006457e57281532409a4d6e891f61208f96ab2b7b7b1746b6
      workingDir: /var/workdir
      volumeMounts:
        - mountPath: /var/lib/containers
          name: varlibcontainers
      env:
        - name: BEARER_TOKEN
          valueFrom:
            secretKeyRef:
              key: token
              name: $(params.BEARER_TOKEN_SECRET_NAME)
              optional: true
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              key: aws_access_key_id
              name: $(params.AWS_SECRET_NAME)
              optional: true
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              key: aws_secret_access_key
              name: $(params.AWS_SECRET_NAME)
              optional: true
      script: |
        #!/bin/bash
        set -e
        set -o pipefail

        download() {
          url="$1"
          file="$2"
          method="GET"

          curl_args=(--fail --silent --show-error)
          if [ -n "${AWS_ACCESS_KEY_ID:-}" ] && [ -n "${AWS_SECRET_ACCESS_KEY:-}" ]; then
            echo "Found both aws credentials secret with both aws_access_key_id and aws_secret_access_key. Assuming S3 bucket"
            # This implements v4 auth https://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-auth-using-authorization-header.html
            path=$(echo "$url" | cut -d/ -f4-)
            echo "Bucket path is $path"
            date="$(date -u '+%Y%m%dT%H%M%SZ')"
            host=$(echo -n "$url" | awk -F '/' '{print $3}')
            region=$(echo -n "$host" | awk -F '.' '{print $2}')

            # This e3b0c44 digest is digest of the empty string. No request body.
            payload_digest=e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855

            # Step 1: construct canonical request
            IFS= read -r -d '' canonical_request <<EOF || true
        $method
        /$path

        host:$host
        x-amz-content-sha256:$payload_digest
        x-amz-date:$date

        host;x-amz-content-sha256;x-amz-date
        $payload_digest
        EOF
            canonical_request=$(echo -n "$canonical_request" | head -c -1) # Strip trailing newline
            canonical_digest=$(echo -n "$canonical_request" | sha256sum | cut -d " " -f 1)

            # Step 2: construct string to sign
            IFS= read -r -d '' string_to_sign <<EOF || true
        AWS4-HMAC-SHA256
        $date
        ${date%T*}/$region/s3/aws4_request
        $canonical_digest
        EOF
            string_to_sign=$(echo -n "$string_to_sign" | head -c -1) # Strip trailing newline

            # Step 3: derive a signing key
            startkey="AWS4${AWS_SECRET_ACCESS_KEY}"
            datekey=$(echo -n "${date%T*}" | openssl dgst -sha256 -hex -hmac "${startkey}" | awk '{ print $2 }' | tr -d '\n')
            dateregionkey=$(echo -n "${region}" | openssl dgst -sha256 -hex -mac HMAC -macopt "hexkey:${datekey}" | awk '{ print $2 }' | tr -d '\n')
            dateregionservicekey=$(echo -n "s3" | openssl dgst -sha256 -hex -mac HMAC -macopt "hexkey:${dateregionkey}" | awk '{ print $2 }' | tr -d '\n')
            signingkey=$(echo -n "aws4_request" | openssl dgst -sha256 -hex -mac HMAC -macopt "hexkey:${dateregionservicekey}" | awk '{ print $2 }' | tr -d '\n')

            # Step 4: use the signing key
            signature=$(echo -n "$string_to_sign" | openssl dgst -sha256 -hex -mac HMAC -macopt "hexkey:${signingkey}" | awk '{ print $2 }' | tr -d '\n')
            authorization="AWS4-HMAC-SHA256 Credential=${AWS_ACCESS_KEY_ID}/${date%T*}/${region}/s3/aws4_request, SignedHeaders=host;x-amz-content-sha256;x-amz-date, Signature=${signature}"

            curl "${curl_args[@]}" \
              -H "X-Amz-Date: ${date}" \
              -H "X-Amz-Content-SHA256: $payload_digest" \
              -H "Authorization: ${authorization}" \
              --location "$url" \
              -o "$file"
          elif [ -n "${BEARER_TOKEN:-}" ]; then
            echo "Found bearer token. Using it for authentication."
            curl "${curl_args[@]}" -H "Authorization: Bearer ${BEARER_TOKEN}" --location "$url" -o "$file"
          else
            echo "Proceeding with anonymous requests"
            curl "${curl_args[@]}" --location "$url" -o "$file"
          fi
        }

        set -u

        echo "Selecting auth for $IMAGE"
        select-oci-auth $IMAGE >auth.json

        echo "Extracting artifact_type"
        ARTIFACT_TYPE=$(cat "$(pwd)/source/$OCI_COPY_FILE" | yq '.artifact_type')

        REPO=${IMAGE%:*}
        echo "Found that ${REPO} is the repository for ${IMAGE}"

        cat >artifact-manifest.json <<EOL
        {
          "schemaVersion": 2,
          "mediaType": "application/vnd.oci.image.manifest.v1+json",
          "artifactType": "${ARTIFACT_TYPE}",
          "config": {
            "mediaType": "application/vnd.oci.empty.v1+json",
            "digest": "sha256:44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
            "size": 2,
            "data": "e30="
          },
          "layers": [],
          "annotations": {
            "org.opencontainers.image.created": "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
          }
        }
        EOL

        echo "Ensuring that the empty blob exists, for the image manifest config."
        echo -n "{}" | oras blob push \
          --registry-config auth.json \
          ${REPO}@sha256:44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a \
          --media-type application/vnd.oci.empty.v1+json --size 2 -

        for varfile in "/var/workdir"/vars/*; do
          echo "Reading $varfile"
          # shellcheck source=/dev/null
          source $varfile

          echo "Checking to see if blob $OCI_ARTIFACT_DIGEST exists"
          if [[ $(oras blob fetch --registry-config auth.json --descriptor "${REPO}@sha256:${OCI_ARTIFACT_DIGEST}") ]]; then
            echo "Blob for ${OCI_FILENAME} already exists in the registry at ${REPO}@sha256:${OCI_ARTIFACT_DIGEST}. Skipping download."
          else
            echo "Blob for ${OCI_FILENAME} does not yet exist in the registry at ${REPO}@sha256:${OCI_ARTIFACT_DIGEST}."
            echo "Downloading $OCI_SOURCE to $OCI_FILENAME"
            download "$OCI_SOURCE" "$OCI_FILENAME"

            echo "Confirming that digest of $OCI_FILENAME matches expected $OCI_ARTIFACT_DIGEST"
            echo "$OCI_ARTIFACT_DIGEST $OCI_FILENAME" | sha256sum --check

            echo "Pushing blob of $OCI_FILENAME of type $OCI_ARTIFACT_TYPE"
            oras blob push --registry-config auth.json ${REPO} --media-type ${OCI_ARTIFACT_TYPE} ${OCI_FILENAME}

            echo "Removing local copy of $OCI_FILENAME to save space."
            rm ${OCI_FILENAME}
          fi

          echo "Grabbing descriptor of blob from the registry"
          oras blob fetch --registry-config auth.json --descriptor "${REPO}@sha256:${OCI_ARTIFACT_DIGEST}" >descriptor.json

          echo "Setting mediaType to ${OCI_ARTIFACT_TYPE}"
          yq -oj -i '.mediaType = "'${OCI_ARTIFACT_TYPE}'"' descriptor.json

          echo "Inserting org.opencontainers.image.title = ${OCI_FILENAME} annotation"
          yq -oj -i '.annotations."org.opencontainers.image.title" = "'${OCI_FILENAME}'"' descriptor.json

          echo "Appending blob descriptor for ${OCI_FILENAME} to the overall artifact manifest for ${IMAGE}"
          yq -oj -i ".layers += $(cat descriptor.json)" artifact-manifest.json

          echo "Done with ${OCI_FILENAME}."
        done

        echo "Pushing complete artifact manifest to ${IMAGE}"
        oras manifest push --no-tty --registry-config auth.json "${IMAGE}" artifact-manifest.json

        RESULTING_DIGEST=$(oras resolve --registry-config auth.json "${IMAGE}")
        echo -n "$RESULTING_DIGEST" | tee "$(results.IMAGE_DIGEST.path)"
        echo -n "$IMAGE" | tee "$(results.IMAGE_URL.path)"
        echo -n "${IMAGE}@${RESULTING_DIGEST}" >"$(results.IMAGE_REF.path)"
      computeResources:
        limits:
          memory: 1Gi
        requests:
          cpu: 250m
          memory: 512Mi
      securityContext:
        capabilities:
          add:
            - SETFCAP
    - name: sbom-generate
      image: quay.io/konflux-ci/yq:latest@sha256:4ce1f9431020387eb6c33a28a46e079b0c28b97f916243d150e70a09e41ce6b4
      workingDir: /var/workdir
      script: |
        #!/bin/bash
        cat >sbom-cyclonedx.json <<EOL
        {
            "\$schema": "http://cyclonedx.org/schema/bom-1.5.schema.json",
            "bomFormat": "CycloneDX",
            "specVersion": "1.5",
            "version": 1,
            "components": []
        }
        EOL

        for varfile in "/var/workdir"/vars/*; do
          echo "Reading $varfile"
          # shellcheck source=/dev/null
          source $varfile

          ENCODED_URL=$(echo "${OCI_SOURCE}" | python3 -c 'import sys; import urllib.parse; print(urllib.parse.quote(sys.stdin.read().strip(), safe=":/"))')
          ENCODED_FILENAME=$(echo "${OCI_FILENAME}" | python3 -c 'import sys; import urllib.parse; print(urllib.parse.quote(sys.stdin.read().strip(), safe=":/"))')
          purl="pkg:generic/${ENCODED_FILENAME}?download_url=${ENCODED_URL}&checksum=sha256:${OCI_ARTIFACT_DIGEST}"

          echo "Recording purl $purl"
          yq -oj -i '.components += [ {"purl": "'$purl'", "type": "file", "name": "'$OCI_FILENAME'", "hashes": [{"alg": "SHA-256", "content": "'$OCI_ARTIFACT_DIGEST'"}], "externalReferences": [{"type": "distribution", "url": "'$OCI_SOURCE'"}]} ]' sbom-cyclonedx.json
        done
    - name: upload-sbom
      image: quay.io/konflux-ci/appstudio-utils:ab6b0b8e40e440158e7288c73aff1cf83a2cc8a9@sha256:24179f0efd06c65d16868c2d7eb82573cce8e43533de6cea14fec3b7446e0b14
      workingDir: /var/workdir
      script: |
        cosign attach sbom --sbom sbom-cyclonedx.json --type cyclonedx "$(cat "$(results.IMAGE_REF.path)")"
    - name: report-sbom-url
      image: quay.io/konflux-ci/yq:latest@sha256:4ce1f9431020387eb6c33a28a46e079b0c28b97f916243d150e70a09e41ce6b4
      workingDir: /var/workdir
      script: |
        #!/bin/bash
        REPO=${IMAGE%:*}
        echo "Found that ${REPO} is the repository for ${IMAGE}"
        SBOM_DIGEST=$(sha256sum sbom-cyclonedx.json | awk '{ print $1 }')
        echo "Found that ${SBOM_DIGEST} is the SBOM digest"
        echo -n "${REPO}@sha256:${SBOM_DIGEST}" | tee $(results.SBOM_BLOB_URL.path)
