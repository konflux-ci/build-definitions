apiVersion: tekton.dev/v1
kind: Task
metadata:
  labels:
    app.kubernetes.io/version: "0.4"
  annotations:
    tekton.dev/pipelines.minVersion: "0.12.1"
    tekton.dev/tags: "konflux"
  name: sast-snyk-check
spec:
  description: |-
    Scans source code for security vulnerabilities, including common issues such as SQL injection, cross-site scripting (XSS), and code injection attacks using Snyk Code, a Static Application Security Testing (SAST) tool.

    Follow the steps given [here](https://konflux-ci.dev/docs/testing/build/snyk/) to obtain a snyk-token and to enable the snyk task in a Pipeline.

    The snyk binary used in this Task comes from a container image defined in https://github.com/konflux-ci/konflux-test

    See https://snyk.io/product/snyk-code/ and https://snyk.io/ for more information about the snyk tool.
  results:
    - description: Tekton task test output.
      name: TEST_OUTPUT
  params:
    - name: SNYK_SECRET
      description: Name of secret which contains Snyk token.
      default: snyk-secret
    - name: ARGS
      type: string
      description: Append arguments.
      default: ""
    - description: Image URL.
      name: image-url
      type: string
    - name: image-digest
      description: Digest of the image to scan.
      type: string
    - name: caTrustConfigMapName
      type: string
      description: The name of the ConfigMap to read CA bundle data from.
      default: trusted-ca
    - name: caTrustConfigMapKey
      type: string
      description: The name of the key in the ConfigMap that contains the CA bundle data.
      default: ca-bundle.crt
    - name: IMP_FINDINGS_ONLY
      type: string
      description: Report only important findings. Default is true. To report all findings, specify "false"
      default: "true"
    - name: KFP_GIT_URL
      type: string
      description: Known False Positives (KFP) git URL (optionally taking
        a revision delimited by \#). Defaults to "SITE_DEFAULT", which means
        the default value "https://gitlab.cee.redhat.com/osh/known-false-positives.git" for internal Konflux
        instance and empty string for external Konflux instance.
        If set to an empty string, the KFP filtering is disabled.

      default: "SITE_DEFAULT"
    - name: PROJECT_NAME
      type: string
      description: Name of the scanned project, used to find path exclusions. By default, the Konflux component name will be used.
      default: ""
    - name: RECORD_EXCLUDED
      type: string
      description: Write excluded records in file. Useful for auditing (defaults to false).
      default: "false"
    - name: IGNORE_FILE_PATHS
      type: string
      description: Directories or files to be excluded from Snyk scan (Comma-separated). Useful to split the directories of a git repo across multiple components.
      default: ""
    - name: TARGET_DIRS
      description: Target directories in component's source code. Multiple values should be separated with commas.
      type: string
      default: "."
  volumes:
    - name: snyk-secret
      secret:
        secretName: $(params.SNYK_SECRET)
        optional: true
    - name: trusted-ca
      configMap:
        name: $(params.caTrustConfigMapName)
        items:
          - key: $(params.caTrustConfigMapKey)
            path: ca-bundle.crt
        optional: true
  steps:
    - name: sast-snyk-check
      computeResources:
        limits:
          memory: 6Gi
        requests:
          cpu: "1"
          memory: 6Gi
      image: quay.io/konflux-ci/konflux-test:v1.4.39@sha256:89cdc9d251e15d07018548137b4034669df8e9e2b171a188c8b8201d3638cb17
      # per https://kubernetes.io/docs/concepts/containers/images/#imagepullpolicy-defaulting
      # the cluster will set imagePullPolicy to IfNotPresent
      workingDir: $(workspaces.workspace.path)/hacbs/$(context.task.name)
      volumeMounts:
        - name: snyk-secret
          mountPath: "/etc/secrets"
          readOnly: true
        - name: trusted-ca
          mountPath: /mnt/trusted-ca
          readOnly: true
      env:
        - name: SNYK_SECRET
          value: $(params.SNYK_SECRET)
        - name: ARGS
          value: $(params.ARGS)
        - name: IGNORE_FILE_PATHS
          value: $(params.IGNORE_FILE_PATHS)
        - name: IMP_FINDINGS_ONLY
          value: $(params.IMP_FINDINGS_ONLY)
        - name: KFP_GIT_URL
          value: $(params.KFP_GIT_URL)
        - name: PROJECT_NAME
          value: $(params.PROJECT_NAME)
        - name: RECORD_EXCLUDED
          value: $(params.RECORD_EXCLUDED)
        - name: COMPONENT_LABEL
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['appstudio.openshift.io/component']
        - name: BUILD_PLR_LOG_URL
          valueFrom:
            fieldRef:
              fieldPath: metadata.annotations['pipelinesascode.tekton.dev/log-url']
        - name: TARGET_DIRS
          value: $(params.TARGET_DIRS)
      script: |
        #!/usr/bin/env bash

        set -euo pipefail
        # shellcheck source=/dev/null
        . /utils.sh
        trap 'handle_error $(results.TEST_OUTPUT.path)' EXIT

        if [[ -z "${PROJECT_NAME}" ]]; then
            PROJECT_NAME=${COMPONENT_LABEL}
        fi

        echo "INFO: The PROJECT_NAME used is: ${PROJECT_NAME}"

        # Installation of Red Hat certificates for cloning Red Hat internal repositories
        ca_bundle=/mnt/trusted-ca/ca-bundle.crt
        if [ -f "$ca_bundle" ]; then
          echo "INFO: Using mounted CA bundle: $ca_bundle"
          cp -vf $ca_bundle /etc/pki/ca-trust/source/anchors
          update-ca-trust
        fi

        SNYK_TOKEN_PATH="/etc/secrets/snyk_token"
        if [ -f "${SNYK_TOKEN_PATH}" ] && [ -s "${SNYK_TOKEN_PATH}" ]; then
          # SNYK token is provided
          SNYK_TOKEN="$(cat ${SNYK_TOKEN_PATH})"
          export SNYK_TOKEN
        else
          # According to shellcheck documentation, the following error can be ignored as it is ignored through indirection: https://www.shellcheck.net/wiki/SC2034
          # shellcheck disable=SC2034
          to_enable_snyk='[here](https://konflux-ci.dev/docs/testing/build/snyk/)'
          note="Task $(context.task.name) skipped: If you wish to use the Snyk code SAST task, please create a secret name snyk-secret with the key 'snyk_token' containing the Snyk token by following the steps given ${to_enable_snyk}"
          TEST_OUTPUT=$(make_result_json -r SKIPPED -t "$note")
          echo "${TEST_OUTPUT}" | tee "$(results.TEST_OUTPUT.path)"
          exit 0
        fi

        SNYK_EXIT_CODE=0
        SOURCE_CODE_DIR=$(workspaces.workspace.path)
        SEVERITY_THRESHOLD="high"
        if [ "${IMP_FINDINGS_ONLY}" == "false" ]; then
          SEVERITY_THRESHOLD="low"
        fi

        # We ignore files using snyk ignore if the user set up the IGNORE_FILE_PATHS variable.
        (cd "${SOURCE_CODE_DIR}" && IFS="," && for path in $IGNORE_FILE_PATHS; do
          snyk ignore --file-path="source/${path}"
        done)

        set +e
        echo "INFO: Running 'snyk code test'.."
        # We do want to expand ARGS (it can be multiple CLI flags, not just one)
        # shellcheck disable=SC2086

        # Generate full paths for each directory in TARGET_DIRS
        IFS="," read -ra TARGETS_ARRAY <<< "$TARGET_DIRS"
        for d in "${TARGETS_ARRAY[@]}"; do
          potential_path="${SOURCE_CODE_DIR}/${d}"
          resolved_path=$(realpath -m "$potential_path")

          # Ensure resolved path is still within SOURCE_CODE_DIR
          if [[ ! "$resolved_path" == "$SOURCE_CODE_DIR"* ]]; then
            echo "Error: path traversal attempt, '$potential_path' is outside '$SOURCE_CODE_DIR'"
            exit 1
          fi

          # Ensure directory exists
          if [ ! -d "$resolved_path" ]; then
            echo "Warning: Directory $resolved_path does not exist, skipping"
            continue
          fi

          echo "INFO: Scanning directory: $resolved_path"
          # We do want to expand ARGS (it can be multiple CLI flags, not just one)
          # shellcheck disable=SC2086
          snyk code test $ARGS --severity-threshold="$SEVERITY_THRESHOLD" "$resolved_path" --max-depth=1 --sarif-file-output="${resolved_path}/sast_snyk_check_out_${d//\//_}.json" 1>&2>> stdout.txt || true
        done

        # Merge all SARIF outputs
        find "$SOURCE_CODE_DIR" -name "sast_snyk_check_out_*.json" -exec cat {} + > "${SOURCE_CODE_DIR}/sast_snyk_check_out.json"

        SNYK_EXIT_CODE=$?
        set -e
        test_not_skipped=0
        SKIP_MSG="We found 0 supported files"
        grep -q "$SKIP_MSG" stdout.txt || test_not_skipped=$?

        if [[ "$SNYK_EXIT_CODE" -eq 0 ]] || [[ "$SNYK_EXIT_CODE" -eq 1 ]]; then
          # Check if the merged SARIF file has content - this could happen if the snyk scan found no findings
          if [ ! -s "${SOURCE_CODE_DIR}/sast_snyk_check_out.json" ]; then
            echo "WARN: No JSON output files were generated by snyk scan"
            # Get snyk version for proper SARIF metadata
            SNYK_VERSION=$(snyk --version 2>/dev/null | head -1 | tr -d '\n' || echo "unknown")
            # Create a valid minimal SARIF structure using jq
            # Note: coverage array is required even when empty because downstream jq commands expect it
            jq -n --arg version "$SNYK_VERSION" '{
              "$schema": "https://json.schemastore.org/sarif-2.1.0.json",
              "version": "2.1.0",
              "runs": [{
                "tool": {
                  "driver": {
                    "name": "snyk",
                    "version": $version,
                    "informationUri": "https://snyk.io"
                  }
                },
                "results": [],
                "properties": {
                  "coverage": []
                }
              }]
            }' >"${SOURCE_CODE_DIR}/sast_snyk_check_out.json"
          fi

          # In order to generate csdiff/v1, we need to add the whole path of the source code as Snyk only provides an URI to embed the context
          (cd  "${SOURCE_CODE_DIR}" && csgrep --mode=json --embed-context=3 "${SOURCE_CODE_DIR}"/sast_snyk_check_out.json) \
            | csgrep --mode=json --strip-path-prefix="source/"  \
            > sast_snyk_check_out_all_findings.json

          echo "INFO: Initial results:"
          csgrep --mode=evtstat sast_snyk_check_out_all_findings.json

          if [[ "${KFP_GIT_URL}" == "SITE_DEFAULT" ]]; then
            KFP_GIT_URL="https://gitlab.cee.redhat.com/osh/known-false-positives.git"
          fi
          PROBE_URL="${KFP_GIT_URL%.git}" # trims '.git' suffix

          # create the KFP clone directory regardless
          KFP_DIR="known-false-positives"
          KFP_CLONED="0"
          mkdir "${KFP_DIR}"

          # We check if the KFP_GIT_URL variable is set to clone and apply the filters or not
          if [[ -n "${KFP_GIT_URL}" ]]; then
            # Default location only reachable from internal Konflux instances, check reachable first
            echo -n "INFO: Probing ${PROBE_URL}... "
            if curl --fail --head --max-time 60 --no-progress-meter "${PROBE_URL}" > >(head -1); then
              echo "INFO: Trying to clone known-false-positives.."
              git clone "${KFP_GIT_URL}" "${KFP_DIR}" && KFP_CLONED="1"
            fi
          fi

          if [[ "${KFP_CLONED}" -eq "0" ]]; then
            echo "WARN: Failed to clone know-false-positives at ${KFP_GIT_URL}, scan results will not be filtered"
            mv sast_snyk_check_out_all_findings.json filtered_sast_snyk_check_out.json
          else
            echo "INFO: Filtering false positives in results files using csfilter-kfp..."

            CMD=(
              csfilter-kfp
              --verbose
              --kfp-dir="${KFP_DIR}"
              --project-nvr="${PROJECT_NAME}"
            )

            if [ "${RECORD_EXCLUDED}" == "true" ]; then
              CMD+=(--record-excluded="excluded-findings.json")
            fi

            set +e
            "${CMD[@]}" sast_snyk_check_out_all_findings.json > filtered_sast_snyk_check_out.json
            status=$?
            set -e
            if [ "$status" -ne 0 ]; then
              echo "WARN: failed to filter known false positives" >&2
            else
              echo "INFO: Succeeded filtering known false positives" >&2
            fi
            echo "INFO: Results after filtering:"
            (set -x && csgrep --mode=evtstat filtered_sast_snyk_check_out.json)
          fi

          # Generation of scan stats

          total_files=$(jq '[.runs[0].properties.coverage[].files] | add' "${SOURCE_CODE_DIR}"/sast_snyk_check_out.json)
          supported_files=$(jq '[.runs[0].properties.coverage[] | select(.type == "SUPPORTED") | .files] | add' "${SOURCE_CODE_DIR}"/sast_snyk_check_out.json)

          # We make sure the values are 0 if no supported/total files are found
          if [ "$total_files" = "null" ] || [ -z "$total_files" ]; then
            total_files=0
          fi

          if [ "$supported_files" = "null" ] || [ -z "$supported_files" ]; then
            supported_files=0
          fi

          coverage_ratio=0
          if (( total_files > 0 )); then
              coverage_ratio=$((supported_files * 100 / total_files))
          fi

          # embed stats in results file and convert to SARIF
          csgrep --mode=sarif --set-scan-prop snyk-scanned-files-coverage:"${coverage_ratio}" \
                              --set-scan-prop snyk-scanned-files-success:"${supported_files}"  \
                              --set-scan-prop snyk-scanned-files-total:"${total_files}" \
                              filtered_sast_snyk_check_out.json  > sast_snyk_check_out.sarif

          TEST_OUTPUT=
          parse_test_output "$(context.task.name)" sarif sast_snyk_check_out.sarif  || true

        # When the test is skipped, the "SNYK_EXIT_CODE" is 3 and it can also be 3 in some other situation
        elif [[ "$test_not_skipped" -eq 0 ]]; then
          note="Task $(context.task.name) success: Snyk code test found zero supported files."
          ERROR_OUTPUT=$(make_result_json -r SUCCESS -t "$note")
        else
          echo "sast-snyk-check test failed because of the following issues:"
          cat stdout.txt
          note="Task $(context.task.name) failed: For details, check Tekton task log."
          ERROR_OUTPUT=$(make_result_json -r ERROR -t "$note")
        fi
        echo "${TEST_OUTPUT:-${ERROR_OUTPUT}}" | tee "$(results.TEST_OUTPUT.path)"
    - name: upload
      computeResources:
        limits:
          memory: 256Mi
        requests:
          cpu: 100m
          memory: 256Mi
      image: quay.io/konflux-ci/oras:latest@sha256:4542f5a2a046ca36653749a8985e46744a5d2d36ee10ca14409be718ce15129e
      workingDir: $(workspaces.workspace.path)/hacbs/$(context.task.name)
      volumeMounts:
        - mountPath: /etc/pki/tls/certs/ca-custom-bundle.crt
          name: trusted-ca
          readOnly: true
          subPath: ca-bundle.crt
      env:
        - name: IMAGE_URL
          value: $(params.image-url)
        - name: IMAGE_DIGEST
          value: $(params.image-digest)
      script: |
        #!/usr/bin/env bash

        if [ -z "${IMAGE_URL}" ]; then
          echo 'No image-url provided. Skipping upload.'
          exit 0
        fi

        UPLOAD_FILES="sast_snyk_check_out.sarif excluded-findings.json stdout.txt"
        for UPLOAD_FILE in ${UPLOAD_FILES}; do
            if [ ! -f "${UPLOAD_FILE}" ]; then
              echo "No ${UPLOAD_FILE} exists. Skipping upload."
              continue
            fi
            if [ "${UPLOAD_FILE}" == "excluded-findings.json" ]; then
                MEDIA_TYPE=application/json
            elif [ "${UPLOAD_FILE}" == "stdout.txt" ]; then
                MEDIA_TYPE=text/plain
            else
                MEDIA_TYPE=application/sarif+json
            fi
            echo "Selecting auth"
            select-oci-auth "${IMAGE_URL}" > "${HOME}/auth.json"
            echo "Attaching to ${IMAGE_URL}"
            if ! retry oras attach --no-tty --registry-config "$HOME/auth.json" --artifact-type "${MEDIA_TYPE}" "${IMAGE_URL}@${IMAGE_DIGEST}" "${UPLOAD_FILE}:${MEDIA_TYPE}"
            then
              echo "Failed to attach to ${IMAGE_URL}"
            fi
        done
  workspaces:
    - name: workspace
