apiVersion: tekton.dev/v1
kind: Task
metadata:
  labels:
    app.kubernetes.io/version: "0.4"
    build.appstudio.redhat.com/build_type: "docker"
  annotations:
    tekton.dev/pipelines.minVersion: "0.12.1"
    tekton.dev/tags: "image-build, konflux"
  name: buildah
spec:
  description: |-
    Buildah task builds source code into a container image and pushes the image into container registry using buildah tool.
    In addition, it generates a SBOM file, injects the SBOM file into final container image and pushes the SBOM file as separate image using cosign tool.
    When prefetch-dependencies task is activated it is using its artifacts to run build in hermetic environment.
  params:
  - description: Reference of the image buildah will produce.
    name: IMAGE
    type: string
  - default: ./Dockerfile
    description: Path to the Dockerfile to build.
    name: DOCKERFILE
    type: string
  - default: .
    description: Path to the directory to use as context.
    name: CONTEXT
    type: string
  - default: "true"
    description: Verify the TLS on the registry endpoint (for push/pull to a non-TLS registry)
    name: TLSVERIFY
    type: string
  - default: "false"
    description: Determines if build will be executed without network access.
    name: HERMETIC
    type: string
  - default: ""
    description: In case it is not empty, the prefetched content should be made available to the build.
    name: PREFETCH_INPUT
    type: string
  - default: ""
    description: Delete image tag after specified time. Empty means to keep the image tag. Time values could be something like 1h, 2d, 3w for hours, days, and weeks, respectively.
    name: IMAGE_EXPIRES_AFTER
    type: string
  - name: COMMIT_SHA
    description: The image is built from this commit.
    type: string
    default: ""
  - name: YUM_REPOS_D_SRC
    description: Path in the git repository in which yum repository files are stored
    default: repos.d
  - name: YUM_REPOS_D_FETCHED
    description: Path in source workspace where dynamically-fetched repos are present
    default: fetched.repos.d
  - name: YUM_REPOS_D_TARGET
    description: Target path on the container in which yum repository files should be made available
    default: /etc/yum.repos.d
  - name: TARGET_STAGE
    description: Target stage in Dockerfile to build. If not specified, the Dockerfile is processed entirely to (and including) its last stage.
    type: string
    default: ""
  - name: ENTITLEMENT_SECRET
    description: Name of secret which contains the entitlement certificates
    type: string
    default: "etc-pki-entitlement"
  - name: ACTIVATION_KEY
    default: activation-key
    description: Name of secret which contains subscription activation key
    type: string
  - name: ADDITIONAL_SECRET
    description: Name of a secret which will be made available to the build with 'buildah build --secret' at /run/secrets/$ADDITIONAL_SECRET
    type: string
    default: "does-not-exist"
  - name: BUILD_ARGS
    description: Array of --build-arg values ("arg=value" strings)
    type: array
    default: []
  - name: BUILD_ARGS_FILE
    description: Path to a file with build arguments, see https://www.mankier.com/1/buildah-build#--build-arg-file
    type: string
    default: ""
  - name: caTrustConfigMapName
    type: string
    description: The name of the ConfigMap to read CA bundle data from.
    default: trusted-ca
  - name: caTrustConfigMapKey
    type: string
    description: The name of the key in the ConfigMap that contains the CA bundle data.
    default: ca-bundle.crt
  - name: ADD_CAPABILITIES
    description: Comma separated list of extra capabilities to add when running 'buildah build'
    type: string
    default: ""
  - name: SQUASH
    description: Squash all new and previous layers added as a part of this build, as per --squash
    type: string
    default: "false"
  - name: STORAGE_DRIVER
    description: Storage driver to configure for buildah
    type: string
    default: vfs
  - name: SKIP_UNUSED_STAGES
    description: Whether to skip stages in Containerfile that seem unused by subsequent stages
    type: string
    default: "true"
  - name: LABELS
    description: Additional key=value labels that should be applied to the image
    type: array
    default: []
  - name: ANNOTATIONS
    description: Additional key=value annotations that should be applied to the image
    type: array
    default: []
  - name: PRIVILEGED_NESTED
    description: Whether to enable privileged mode, should be used only with remote VMs
    type: string
    default: "false"
  - name: SKIP_SBOM_GENERATION
    description: Skip SBOM-related operations. This will likely cause EC policies to fail if enabled
    type: string
    default: "false"
  - name: SBOM_TYPE
    description: >-
      Select the SBOM format to generate. Valid values: spdx, cyclonedx.
      Note: the SBOM from the prefetch task - if there is one - must be in the same format.
    type: string
    default: spdx
  - name: BUILDAH_FORMAT
    description: The format for the resulting image's mediaType. Valid values are oci (default) or docker.
    type: string
    default: oci
  - name: ADDITIONAL_BASE_IMAGES
    description: |-
      Additional base image references to include to the SBOM. Array of image_reference_with_digest strings
    type: array
    default: []

  results:
  - description: Digest of the image just built
    name: IMAGE_DIGEST
  - description: Image repository and tag where the built image was pushed
    name: IMAGE_URL
  - description: Image reference of the built image
    name: IMAGE_REF
  - name: SBOM_BLOB_URL
    description: Reference of SBOM blob digest to enable digest-based verification from provenance
    type: string
  stepTemplate:
    computeResources:
      limits:
        memory: 4Gi
      requests:
        memory: 1Gi
        cpu: '1'
    volumeMounts:
      - mountPath: /shared
        name: shared
    env:
    - name: STORAGE_DRIVER
      value: $(params.STORAGE_DRIVER)
    - name: HERMETIC
      value: $(params.HERMETIC)
    - name: SOURCE_CODE_DIR
      value: source
    - name: CONTEXT
      value: $(params.CONTEXT)
    - name: IMAGE
      value: $(params.IMAGE)
    - name: TLSVERIFY
      value: $(params.TLSVERIFY)
    - name: IMAGE_EXPIRES_AFTER
      value: $(params.IMAGE_EXPIRES_AFTER)
    - name: YUM_REPOS_D_SRC
      value: $(params.YUM_REPOS_D_SRC)
    - name: YUM_REPOS_D_FETCHED
      value: $(params.YUM_REPOS_D_FETCHED)
    - name: YUM_REPOS_D_TARGET
      value: $(params.YUM_REPOS_D_TARGET)
    - name: TARGET_STAGE
      value: $(params.TARGET_STAGE)
    - name: ENTITLEMENT_SECRET
      value: $(params.ENTITLEMENT_SECRET)
    - name: ACTIVATION_KEY
      value: $(params.ACTIVATION_KEY)
    - name: ADDITIONAL_SECRET
      value: $(params.ADDITIONAL_SECRET)
    - name: BUILD_ARGS_FILE
      value: $(params.BUILD_ARGS_FILE)
    - name: ADD_CAPABILITIES
      value: $(params.ADD_CAPABILITIES)
    - name: SQUASH
      value: $(params.SQUASH)
    - name: SKIP_UNUSED_STAGES
      value: $(params.SKIP_UNUSED_STAGES)
    - name: PRIVILEGED_NESTED
      value: $(params.PRIVILEGED_NESTED)
    - name: SKIP_SBOM_GENERATION
      value: $(params.SKIP_SBOM_GENERATION)
    - name: SBOM_TYPE
      value: $(params.SBOM_TYPE)

  steps:
  - image: quay.io/konflux-ci/buildah-task:latest@sha256:ab0ba3b70f99faa74d2dd737422a965197af4922dec0109113bc535a94db0dfd
    name: build
    computeResources:
      limits:
        memory: 8Gi
      requests:
        memory: 2Gi
        cpu: '1'
    env:
    - name: COMMIT_SHA
      value: $(params.COMMIT_SHA)
    - name: DOCKERFILE
      value: $(params.DOCKERFILE)
    args:
      - --build-args
      - $(params.BUILD_ARGS[*])
      - --labels
      - $(params.LABELS[*])
      - --annotations
      - $(params.ANNOTATIONS[*])

    script: |
      #!/bin/bash
      set -euo pipefail

      echo "[$(date --utc -Ins)] Update CA trust"

      ca_bundle=/mnt/trusted-ca/ca-bundle.crt
      if [ -f "$ca_bundle" ]; then
        echo "INFO: Using mounted CA bundle: $ca_bundle"
        cp -vf $ca_bundle /etc/pki/ca-trust/source/anchors
        update-ca-trust
      fi

      echo "[$(date --utc -Ins)] Prepare Dockerfile"

      if [ -e "$SOURCE_CODE_DIR/$CONTEXT/$DOCKERFILE" ]; then
        dockerfile_path="$(pwd)/$SOURCE_CODE_DIR/$CONTEXT/$DOCKERFILE"
      elif [ -e "$SOURCE_CODE_DIR/$DOCKERFILE" ]; then
        dockerfile_path="$(pwd)/$SOURCE_CODE_DIR/$DOCKERFILE"
      elif [ -e "$DOCKERFILE" ]; then
        # Instrumented builds (SAST) use this custom dockerfile step as their base
        dockerfile_path="$DOCKERFILE"
      elif echo "$DOCKERFILE" | grep -q "^https\?://"; then
        echo "Fetch Dockerfile from $DOCKERFILE"
        dockerfile_path=$(mktemp --suffix=-Dockerfile)
        http_code=$(curl -s -S -L -w "%{http_code}" --output "$dockerfile_path" "$DOCKERFILE")
        if [ "$http_code" != 200 ]; then
          echo "No Dockerfile is fetched. Server responds $http_code"
          exit 1
        fi
        http_code=$(curl -s -S -L -w "%{http_code}" --output "$dockerfile_path.dockerignore.tmp" "$DOCKERFILE.dockerignore")
        if [ "$http_code" = 200 ]; then
          echo "Fetched .dockerignore from $DOCKERFILE.dockerignore"
          mv "$dockerfile_path.dockerignore.tmp" "$SOURCE_CODE_DIR/$CONTEXT/.dockerignore"
        fi
      else
        echo "Cannot find Dockerfile $DOCKERFILE"
        exit 1
      fi

      dockerfile_copy=$(mktemp --tmpdir "$(basename "$dockerfile_path").XXXXXX")
      cp "$dockerfile_path" "$dockerfile_copy"

      echo "[$(date --utc -Ins)] Prepare system"

      # Fixing group permission on /var/lib/containers
      chown root:root /var/lib/containers

      sed -i 's/^\s*short-name-mode\s*=\s*.*/short-name-mode = "disabled"/' /etc/containers/registries.conf

      # Setting new namespace to run buildah - 2^32-2
      echo 'root:1:4294967294' | tee -a /etc/subuid >> /etc/subgid

      build_args=()
      if [ -n "${BUILD_ARGS_FILE}" ]; then
        # Parse BUILD_ARGS_FILE ourselves because dockerfile-json doesn't support it
        echo "Parsing ARGs from $BUILD_ARGS_FILE"
        mapfile -t build_args < <(
          # https://www.mankier.com/1/buildah-build#--build-arg-file
          # delete lines that start with #
          # delete blank lines
          sed -e '/^#/d' -e '/^\s*$/d' "${SOURCE_CODE_DIR}/${BUILD_ARGS_FILE}"
        )
      fi

      LABELS=()
      ANNOTATIONS=()
      # Split `args` into two sets of arguments.
      while [[ $# -gt 0 ]]; do
          case $1 in
              --build-args)
                  shift
                  # Note: this may result in multiple --build-arg=KEY=value flags with the same KEY being
                  # passed to buildah. In that case, the *last* occurrence takes precedence. This is why
                  # we append BUILD_ARGS after the content of the BUILD_ARGS_FILE
                  while [[ $# -gt 0 && $1 != --* ]]; do build_args+=("$1"); shift; done
                  ;;
              --labels)
                  shift
                  while [[ $# -gt 0 && $1 != --* ]]; do LABELS+=("--label" "$1"); shift; done
                  ;;
              --annotations)
                  shift
                  while [[ $# -gt 0 && $1 != --* ]]; do ANNOTATIONS+=("--annotation" "$1"); shift; done
                  ;;
              *)
                  echo "unexpected argument: $1" >&2
                  exit 2
                  ;;
          esac
      done

      BUILD_ARG_FLAGS=()
      for build_arg in "${build_args[@]}"; do
        BUILD_ARG_FLAGS+=("--build-arg=$build_arg")
      done

      dockerfile-json "${BUILD_ARG_FLAGS[@]}" "$dockerfile_copy" > /shared/parsed_dockerfile.json
      BASE_IMAGES=$(
          jq -r '.Stages[] | select(.From | .Stage or .Scratch | not) | .BaseName | select(test("^oci-archive:") | not)' /shared/parsed_dockerfile.json |
            tr -d '"' |
            tr -d "'"
      )

      BUILDAH_ARGS=()
      UNSHARE_ARGS=()

      if [ "${HERMETIC}" == "true" ]; then
        BUILDAH_ARGS+=("--pull=never")
        UNSHARE_ARGS+=("--net")

        for image in $BASE_IMAGES; do
          unshare -Ufp --keep-caps -r --map-users 1,1,65536 --map-groups 1,1,65536 -- buildah pull "$image"
        done
        echo "Build will be executed with network isolation"
      fi

      if [ -n "${TARGET_STAGE}" ]; then
        BUILDAH_ARGS+=("--target=${TARGET_STAGE}")
      fi

      BUILDAH_ARGS+=("${BUILD_ARG_FLAGS[@]}")

      if [ "${PRIVILEGED_NESTED}" == "true" ]; then
        BUILDAH_ARGS+=("--security-opt=label=disable")
        BUILDAH_ARGS+=("--cap-add=all")
        BUILDAH_ARGS+=("--device=/dev/fuse")
      fi

      if [ -n "${ADD_CAPABILITIES}" ]; then
        BUILDAH_ARGS+=("--cap-add=${ADD_CAPABILITIES}")
      fi

      if [ "${SQUASH}" == "true" ]; then
        BUILDAH_ARGS+=("--squash")
      fi

      if [ "${SKIP_UNUSED_STAGES}" != "true" ] ; then
        BUILDAH_ARGS+=("--skip-unused-stages=false")
      fi

      VOLUME_MOUNTS=()

      echo "[$(date --utc -Ins)] Setup prefetched"

      if [ -f "$(workspaces.source.path)/cachi2/cachi2.env" ]; then
        cp -r "$(workspaces.source.path)/cachi2" /tmp/
        chmod -R go+rwX /tmp/cachi2
        VOLUME_MOUNTS+=(--volume /tmp/cachi2:/cachi2)
        # Read in the whole file (https://unix.stackexchange.com/questions/533277), then
        # for each RUN ... line insert the cachi2.env command *after* any options like --mount
        sed -E -i \
            -e 'H;1h;$!d;x' \
            -e 's@^\s*(run((\s|\\\n)+-\S+)*(\s|\\\n)+)@\1. /cachi2/cachi2.env \&\& \\\n    @igM' \
            "$dockerfile_copy"
        echo "Prefetched content will be made available"

        prefetched_repo_for_my_arch="/tmp/cachi2/output/deps/rpm/$(uname -m)/repos.d/cachi2.repo"
        if [ -f "$prefetched_repo_for_my_arch" ]; then
          echo "Adding $prefetched_repo_for_my_arch to $YUM_REPOS_D_FETCHED"
          mkdir -p "$YUM_REPOS_D_FETCHED"
          if [ ! -f "${YUM_REPOS_D_FETCHED}/cachi2.repo" ]; then
            cp "$prefetched_repo_for_my_arch" "$YUM_REPOS_D_FETCHED"
          fi
        fi
      fi

      # if yum repofiles stored in git, copy them to mount point outside the source dir
      if [ -d "${SOURCE_CODE_DIR}/${YUM_REPOS_D_SRC}" ]; then
        mkdir -p "${YUM_REPOS_D_FETCHED}"
        cp -r "${SOURCE_CODE_DIR}/${YUM_REPOS_D_SRC}"/* "${YUM_REPOS_D_FETCHED}"
      fi

      # if anything in the repofiles mount point (either fetched or from git), mount it
      if [ -d "${YUM_REPOS_D_FETCHED}" ]; then
        chmod -R go+rwX "${YUM_REPOS_D_FETCHED}"
        mount_point=$(realpath "${YUM_REPOS_D_FETCHED}")
        VOLUME_MOUNTS+=(--volume "${mount_point}:${YUM_REPOS_D_TARGET}")
      fi

      DEFAULT_LABELS=(
        "--label" "build-date=$(date -u +'%Y-%m-%dT%H:%M:%S')"
        "--label" "architecture=$(uname -m)"
        "--label" "vcs-type=git"
      )
      [ -n "$COMMIT_SHA" ] && DEFAULT_LABELS+=("--label" "vcs-ref=$COMMIT_SHA")
      [ -n "$IMAGE_EXPIRES_AFTER" ] && DEFAULT_LABELS+=("--label" "quay.expires-after=$IMAGE_EXPIRES_AFTER")

      # Concatenate defaults and explicit labels. If a label appears twice, the last one wins.
      LABELS=("${DEFAULT_LABELS[@]}" "${LABELS[@]}")

      echo "[$(date --utc -Ins)] Register sub-man"

      ACTIVATION_KEY_PATH="/activation-key"
      ENTITLEMENT_PATH="/entitlement"

      # 0. if hermetic=true, skip all subscription related stuff
      # 1. do not enable activation key and entitlement at same time. If both vars are provided, prefer activation key.
      # 2. Activation-keys will be used when the key 'org' exists in the activation key secret.
      # 3. try to pre-register and mount files to the correct location so that users do no need to modify Dockerfiles.
      # 3. If the Dockerfile contains the string "subcription-manager register", add the activation-keys volume
      #    to buildah but don't pre-register for backwards compatibility. Mount an empty directory on
      #    shared emptydir volume to "/etc/pki/entitlement" to prevent certificates from being included

      if [ "${HERMETIC}" != "true" ] && [ -e /activation-key/org ]; then
        cp -r --preserve=mode "$ACTIVATION_KEY_PATH" /tmp/activation-key
        mkdir -p /shared/rhsm/etc/pki/entitlement
        mkdir -p /shared/rhsm/etc/pki/consumer

        VOLUME_MOUNTS+=(-v /tmp/activation-key:/activation-key \
                        -v /shared/rhsm/etc/pki/entitlement:/etc/pki/entitlement:Z \
                        -v /shared/rhsm/etc/pki/consumer:/etc/pki/consumer:Z)
        echo "Adding activation key to the build"

        if ! grep -E "^[^#]*subscription-manager.[^#]*register" "$dockerfile_path"; then
          # user is not running registration in the Containerfile: pre-register.
          echo "Pre-registering with subscription manager."
          subscription-manager register --org "$(cat /tmp/activation-key/org)" --activationkey "$(cat /tmp/activation-key/activationkey)"
          trap 'subscription-manager unregister || true' EXIT

          # copy generated certificates to /shared volume
          cp /etc/pki/entitlement/*.pem /shared/rhsm/etc/pki/entitlement
          cp /etc/pki/consumer/*.pem /shared/rhsm/etc/pki/consumer

          # and then mount get /etc/rhsm/ca/redhat-uep.pem into /run/secrets/rhsm/ca
          VOLUME_MOUNTS+=(--volume /etc/rhsm/ca/redhat-uep.pem:/etc/rhsm/ca/redhat-uep.pem:Z)
        fi

      elif [ "${HERMETIC}" != "true" ] && find /entitlement -name "*.pem" >> null; then
        cp -r --preserve=mode "$ENTITLEMENT_PATH" /tmp/entitlement
        VOLUME_MOUNTS+=(--volume /tmp/entitlement:/etc/pki/entitlement)
        echo "Adding the entitlement to the build"
      fi

      if [ -n "${ADDITIONAL_VOLUME_MOUNTS-}" ]; then
        # ADDITIONAL_VOLUME_MOUNTS allows to specify more volumes for the build.
        # Instrumented builds (SAST) use this step as their base and add some other tools.
        while read -r volume_mount; do
          VOLUME_MOUNTS+=("--volume=$volume_mount")
        done <<< "$ADDITIONAL_VOLUME_MOUNTS"
      fi

      echo "[$(date --utc -Ins)] Add secrets"

      ADDITIONAL_SECRET_PATH="/additional-secret"
      ADDITIONAL_SECRET_TMP="/tmp/additional-secret"
      if [ -d "$ADDITIONAL_SECRET_PATH" ]; then
        cp -r --preserve=mode -L "$ADDITIONAL_SECRET_PATH" $ADDITIONAL_SECRET_TMP
        while read -r filename; do
          echo "Adding the secret ${ADDITIONAL_SECRET}/${filename} to the build, available at /run/secrets/${ADDITIONAL_SECRET}/${filename}"
          BUILDAH_ARGS+=("--secret=id=${ADDITIONAL_SECRET}/${filename},src=$ADDITIONAL_SECRET_TMP/${filename}")
        done < <(find $ADDITIONAL_SECRET_TMP -maxdepth 1 -type f -exec basename {} \;)
      fi

      # Prevent ShellCheck from giving a warning because 'image' is defined and 'IMAGE' is not.
      declare IMAGE

      buildah_cmd_array=(
          buildah build
          "${VOLUME_MOUNTS[@]}"
          "${BUILDAH_ARGS[@]}"
          "${LABELS[@]}"
          "${ANNOTATIONS[@]}"
          --tls-verify="$TLSVERIFY" --no-cache
          --ulimit nofile=4096:4096
          -f "$dockerfile_copy" -t "$IMAGE" .
      )
      buildah_cmd=$(printf "%q " "${buildah_cmd_array[@]}")

      if [ "${HERMETIC}" == "true" ]; then
        # enabling loopback adapter enables Bazel builds to work in hermetic mode.
        command="ip link set lo up && $buildah_cmd"
      else
        command="$buildah_cmd"
      fi

      # disable host subcription manager integration
      find /usr/share/rhel/secrets -type l -exec unlink {} \;

      echo "[$(date --utc -Ins)] Run buildah build"

      unshare -Uf "${UNSHARE_ARGS[@]}" --keep-caps -r --map-users 1,1,65536 --map-groups 1,1,65536 -w "${SOURCE_CODE_DIR}/$CONTEXT" -- sh -c "$command"

      echo "[$(date --utc -Ins)] Add metadata"

      container=$(buildah from --pull-never "$IMAGE")

      # Save the SBOM produced by Cachi2 so it can be merged into the final SBOM later
      if [ -f "/tmp/cachi2/output/bom.json" ]; then
        echo "Making copy of sbom-cachi2.json"
        cp /tmp/cachi2/output/bom.json ./sbom-cachi2.json
      fi

      buildah mount "$container" | tee /shared/container_path
      # delete symlinks - they may point outside the container rootfs, messing with SBOM scanners
      find $(cat /shared/container_path) -xtype l -delete
      echo $container > /shared/container_name

      touch /shared/base_images_digests
      echo "Recording base image digests used"
      for image in $BASE_IMAGES; do
        base_image_digest=$(buildah images --format '{{ .Name }}:{{ .Tag }}@{{ .Digest }}' --filter reference="$image")
        # In some cases, there might be BASE_IMAGES, but not any associated digest. This happens
        # if buildah did not use that particular image during build because it was skipped
        if [ -n "$base_image_digest" ]; then
          echo "$image $base_image_digest" | tee -a /shared/base_images_digests
        fi
      done

      echo "[$(date --utc -Ins)] End build"

    securityContext:
      capabilities:
        add:
          - SETFCAP
    volumeMounts:
    - mountPath: /var/lib/containers
      name: varlibcontainers
    - mountPath: "/entitlement"
      name: etc-pki-entitlement
    - mountPath: /activation-key
      name: activation-key
    - mountPath: "/additional-secret"
      name: additional-secret
    - name: trusted-ca
      mountPath: /mnt/trusted-ca
      readOnly: true
    workingDir: $(workspaces.source.path)
  - name: icm
    image: quay.io/konflux-ci/icm-injection-scripts:latest@sha256:f7a57ec2435029b2bed6866b3dddb97027f22bb81b2648bb450c9073e4c4f65e
    securityContext:
      capabilities:
        add:
          - SETFCAP
    volumeMounts:
    - mountPath: /var/lib/containers
      name: varlibcontainers
    workingDir: $(workspaces.source.path)
    script: |
      #!/bin/bash
      set -euo pipefail
      /scripts/inject-icm.sh "$IMAGE"
  - name: push
    image: quay.io/konflux-ci/buildah-task:latest@sha256:ab0ba3b70f99faa74d2dd737422a965197af4922dec0109113bc535a94db0dfd
    env:
    - name: BUILDAH_FORMAT
      value: $(params.BUILDAH_FORMAT)
    script: |
      #!/bin/bash
      set -e

      echo "[$(date --utc -Ins)] Update CA trust"

      ca_bundle=/mnt/trusted-ca/ca-bundle.crt
      if [ -f "$ca_bundle" ]; then
        echo "INFO: Using mounted CA bundle: $ca_bundle"
        cp -vf $ca_bundle /etc/pki/ca-trust/source/anchors
        update-ca-trust
      fi

      echo "[$(date --utc -Ins)] Convert image"

      # While we can build images with the desired format, we will simplify any local
      # and remote build differences by just performing any necessary conversions at
      # push time.
      push_format=oci
      if [ "${BUILDAH_FORMAT}" == "docker" ]; then
        push_format=docker
      fi

      echo "[$(date --utc -Ins)] Push image with unique tag"

      retries=5
      # Push to a unique tag based on the TaskRun name to avoid race conditions
      echo "Pushing to ${IMAGE%:*}:${TASKRUN_NAME}"
      if ! buildah push \
        --format="$push_format" \
        --retry "$retries" \
        --tls-verify="$TLSVERIFY" \
        "$IMAGE" \
        "docker://${IMAGE%:*}:$(context.taskRun.name)";
      then
        echo "Failed to push sbom image to ${IMAGE%:*}:$(context.taskRun.name) after ${retries} tries"
        exit 1
      fi

      echo "[$(date --utc -Ins)] Push image with git revision"

      # Push to a tag based on the git revision
      echo "Pushing to ${IMAGE}"
      if ! buildah push \
        --format="$push_format" \
        --retry "$retries" \
        --tls-verify="$TLSVERIFY" \
        --digestfile "$(workspaces.source.path)/image-digest" "$IMAGE" \
        "docker://$IMAGE";
      then
        echo "Failed to push sbom image to $IMAGE after ${retries} tries"
        exit 1
      fi

      cat "$(workspaces.source.path)"/image-digest | tee $(results.IMAGE_DIGEST.path)
      echo -n "$IMAGE" | tee $(results.IMAGE_URL.path)
      {
        echo -n "${IMAGE}@"
        cat "$(workspaces.source.path)/image-digest"
      } > "$(results.IMAGE_REF.path)"

      echo
      echo "[$(date --utc -Ins)] End push"

    securityContext:
      runAsUser: 0
      capabilities:
        add:
          - SETFCAP
    volumeMounts:
    - mountPath: /var/lib/containers
      name: varlibcontainers
    - name: trusted-ca
      mountPath: /mnt/trusted-ca
      readOnly: true
    workingDir: $(workspaces.source.path)

  - name: sbom-syft-generate
    image: registry.access.redhat.com/rh-syft-tech-preview/syft-rhel9:1.19.0@sha256:070ecb89de5104bb64fbf399a991a975e7d4d7e0cea0f7beb1e591b5591991c8
    # Respect Syft configuration if the user has it in the root of their repository
    # (need to set the workdir, see https://github.com/anchore/syft/issues/2465)
    workingDir: $(workspaces.source.path)/source
    script: |
      echo "[$(date --utc -Ins)] Generate SBOM"

      if [ "${SKIP_SBOM_GENERATION}" = "true" ]; then
        echo "Skipping SBOM generation"
        exit 0
      fi

      case $SBOM_TYPE in
        cyclonedx)
          syft_sbom_type=cyclonedx-json@1.5 ;;
        spdx)
          syft_sbom_type=spdx-json@2.3 ;;
        *)
          echo "Invalid SBOM type: $SBOM_TYPE. Valid: cyclonedx, spdx" >&2
          exit 1
          ;;
      esac

      echo "Running syft on the source directory"
      syft dir:"$(workspaces.source.path)/$SOURCE_CODE_DIR/$CONTEXT" --output "$syft_sbom_type"="$(workspaces.source.path)/sbom-source.json"
      echo "Running syft on the image filesystem"
      syft dir:"$(cat /shared/container_path)" --output "$syft_sbom_type"="$(workspaces.source.path)/sbom-image.json"

      echo "[$(date --utc -Ins)] End sbom-syft-generate"
    volumeMounts:
    - mountPath: /var/lib/containers
      name: varlibcontainers
    - mountPath: /shared
      name: shared

  - name: prepare-sboms
    image: quay.io/konflux-ci/sbom-utility-scripts@sha256:d90b3ed72cff083ab8238241df8b91d86d270b92d5d10eda16c70d55d02c211d
    computeResources:
      limits:
        memory: 512Mi
      requests:
        memory: 256Mi
        cpu: 100m
    args:
      - --additional-base-images
      - $(params.ADDITIONAL_BASE_IMAGES[*])
    script: |
      #!/bin/bash
      set -euo pipefail

      echo "[$(date --utc -Ins)] Prepare SBOM"

      if [ "${SKIP_SBOM_GENERATION}" = "true" ]; then
        echo "Skipping SBOM generation"
        exit 0
      fi

      sboms_to_merge=(syft:sbom-source.json syft:sbom-image.json)

      if [ -f "sbom-cachi2.json" ]; then
        sboms_to_merge+=(cachi2:sbom-cachi2.json)
      fi

      echo "Merging sboms: (${sboms_to_merge[*]}) => sbom.json"
      python3 /scripts/merge_sboms.py "${sboms_to_merge[@]}" > sbom.json

      echo "Adding image reference to sbom"
      IMAGE_URL="$(cat "$(results.IMAGE_URL.path)")"
      IMAGE_DIGEST="$(cat "$(results.IMAGE_DIGEST.path)")"

      python3 /scripts/add_image_reference.py \
        --image-url "$IMAGE_URL" \
        --image-digest "$IMAGE_DIGEST" \
        --input-file sbom.json \
        --output-file /tmp/sbom.tmp.json

      mv /tmp/sbom.tmp.json sbom.json

      echo "Adding base images data to sbom.json"
      python3 /scripts/base_images_sbom_script.py \
        --sbom=sbom.json \
        --parsed-dockerfile=/shared/parsed_dockerfile.json \
        --base-images-digests=/shared/base_images_digests

      ADDITIONAL_BASE_IMAGES=()
      while [[ $# -gt 0 ]]; do
        case $1 in
          --additional-base-images)
            shift
            while [[ $# -gt 0 && $1 != --* ]]
            do
              ADDITIONAL_BASE_IMAGES+=("$1")
              shift
            done
            ;;
          *)
            echo "unexpected argument: $1" >&2
            exit 2
            ;;
        esac
      done

      for ADDITIONAL_BASE_IMAGE in "${ADDITIONAL_BASE_IMAGES[@]}"; do
        IFS="@" read -ra BASE_IMAGE <<< "${ADDITIONAL_BASE_IMAGE}"
        python3 /scripts/add_image_reference.py \
          --builder-image \
          --image-url "${BASE_IMAGE[0]}" \
          --image-digest "${BASE_IMAGE[1]}" \
          --input-file sbom.json \
          --output-file /tmp/sbom.tmp.json
        mv /tmp/sbom.tmp.json sbom.json
      done

      echo "[$(date --utc -Ins)] End prepare-sboms"
    workingDir: $(workspaces.source.path)
    securityContext:
      runAsUser: 0

  - name: upload-sbom
    image: quay.io/konflux-ci/appstudio-utils:48c311af02858e2422d6229600e9959e496ddef1@sha256:91ddd999271f65d8ec8487b10f3dd378f81aa894e11b9af4d10639fd52bba7e8
    script: |
      #!/bin/bash

      echo "[$(date --utc -Ins)] Upload SBOM"

      if [ "${SKIP_SBOM_GENERATION}" = "true" ]; then
        echo "Skipping SBOM generation"
        exit 0
      fi

      ca_bundle=/mnt/trusted-ca/ca-bundle.crt
      if [ -f "$ca_bundle" ]; then
        echo "INFO: Using mounted CA bundle: $ca_bundle"
        cp -vf $ca_bundle /etc/pki/ca-trust/source/anchors
        update-ca-trust
      fi

      cosign attach sbom --sbom sbom.json --type "$SBOM_TYPE" "$(cat "$(results.IMAGE_REF.path)")"

      # Remove tag from IMAGE while allowing registry to contain a port number.
      sbom_repo="${IMAGE%:*}"
      sbom_digest="$(sha256sum sbom.json | cut -d' ' -f1)"
      # The SBOM_BLOB_URL is created by `cosign attach sbom`.
      echo -n "${sbom_repo}@sha256:${sbom_digest}" | tee "$(results.SBOM_BLOB_URL.path)"

      echo
      echo "[$(date --utc -Ins)] End upload-sbom"

    computeResources:
      limits:
        memory: 512Mi
      requests:
        memory: 256Mi
        cpu: 100m
    volumeMounts:
    - name: trusted-ca
      mountPath: /mnt/trusted-ca
      readOnly: true
    workingDir: $(workspaces.source.path)

  volumes:
  - name: varlibcontainers
    emptyDir: {}
  - name: shared
    emptyDir: {}
  - name: etc-pki-entitlement
    secret:
      secretName: $(params.ENTITLEMENT_SECRET)
      optional: true
  - name: activation-key
    secret:
      optional: true
      secretName: $(params.ACTIVATION_KEY)
  - name: additional-secret
    secret:
      secretName: $(params.ADDITIONAL_SECRET)
      optional: true
  - name: trusted-ca
    configMap:
      name: $(params.caTrustConfigMapName)
      items:
        - key: $(params.caTrustConfigMapKey)
          path: ca-bundle.crt
      optional: true
  workspaces:
  - name: source
    description: Workspace containing the source code to build.
