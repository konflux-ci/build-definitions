apiVersion: tekton.dev/v1
kind: Task
metadata:
  annotations:
    tekton.dev/pipelines.minVersion: 0.12.1
    tekton.dev/tags: image-build, konflux
  labels:
    app.kubernetes.io/version: "0.1"
    build.appstudio.redhat.com/build_type: oci-artifact
  name: oci-copy
spec:
  description: Given a file in the user's source directory, copy content from arbitrary urls into the OCI registry.
  params:
    - description: Reference of the image we will push
      name: IMAGE
      type: string
    - default: ./oci-copy.yaml
      description: Path to the oci copy file.
      name: OCI_COPY_FILE
      type: string
    - name: BEARER_TOKEN_SECRET_NAME
      description: >-
        Name of a secret which will be made available to the build as an Authorization header. Note, the token will
        be sent to all servers found in the oci-copy.yaml file. If you do not wish to send the token to all servers,
        different taskruns and therefore different oci artifacts must be used.
      type: string
      default: "does-not-exist"
    - name: AWS_SECRET_NAME
      description: >-
        Name of a secret which will be made available to the build to construct Authorization headers for requests to
        Amazon S3 using v2 auth https://docs.aws.amazon.com/AmazonS3/latest/userguide/RESTAuthentication.html.
        If specified, this will take precedence over BEARER_TOKEN_SECRET_NAME. The secret must contain two keys:
        `aws_access_key_id` and `aws_secret_access_key`. In the future, this will be reimplemented to use v4 auth:
        https://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-auth-using-authorization-header.html.
      type: string
      default: "does-not-exist"
    - name: SBOM_TYPE
      description: "Select the SBOM format to generate. Valid values: spdx, cyclonedx."
      type: string
      default: cyclonedx

  results:
    - description: Digest of the artifact just pushed
      name: IMAGE_DIGEST
    - description: Repository where the artifact was pushed
      name: IMAGE_URL
    - description: Link to the SBOM blob pushed to the registry.
      name: SBOM_BLOB_URL
    - name: IMAGE_REF
      description: Image reference of the built image
  stepTemplate:
    env:
      - name: OCI_COPY_FILE
        value: $(params.OCI_COPY_FILE)
      - name: IMAGE
        value: $(params.IMAGE)
      - name: SBOM_TYPE
        value: $(params.SBOM_TYPE)
  steps:
    - name: prepare
      image: quay.io/konflux-ci/yq:latest@sha256:93bb15cff64b708263055a5814b24a0b450d8724b86a7e5206396f25d81fcc21
      script: |
        #!/bin/bash
        set -eu
        set -o pipefail

        oci_copy_file_path="$(pwd)/source/$OCI_COPY_FILE"

        mkdir -p "$(workspaces.source.path)/vars/"

        for entry in $(cat $oci_copy_file_path | yq '.artifacts[] | @json | @base64'); do
          entry=$(echo $entry | base64 -d)
          source=$(echo $entry | yq .source)
          filename=$(echo $entry | yq .filename)
          artifact_type=$(echo $entry | yq .type)
          artifact_digest=$(echo $entry | yq .sha256sum)

          {
            echo "declare OCI_SOURCE=${source}";
            echo "declare OCI_FILENAME=${filename}";
            echo "declare OCI_ARTIFACT_TYPE=${artifact_type}";
            echo "declare OCI_ARTIFACT_DIGEST=${artifact_digest}";
          } > "$(workspaces.source.path)/vars/$filename"

          echo "Wrote $(workspaces.source.path)/vars/$filename with contents:"
          cat "$(workspaces.source.path)/vars/$filename"
        done
      workingDir: $(workspaces.source.path)
    - name: oci-copy
      image: quay.io/konflux-ci/oras:latest@sha256:c68c23fe7bb1ba9fc335192761ea94fc2c9beb701f3c205890581ff62fd38d80
      computeResources:
        limits:
          memory: 1Gi
        requests:
          cpu: 250m
          memory: 512Mi
      securityContext:
        capabilities:
          add:
            - SETFCAP
      env:
      - name: BEARER_TOKEN
        valueFrom:
          secretKeyRef:
            name: $(params.BEARER_TOKEN_SECRET_NAME)
            key: token
            optional: true
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: $(params.AWS_SECRET_NAME)
            key: aws_access_key_id
            optional: true
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: $(params.AWS_SECRET_NAME)
            key: aws_secret_access_key
            optional: true
      script: |
        #!/bin/bash
        set -e
        set -o pipefail

        download() {
          url="$1"
          file="$2"
          method="GET"

          curl_args=(--fail --silent --show-error)
          if [ -n "${AWS_ACCESS_KEY_ID:-}" ] && [ -n "${AWS_SECRET_ACCESS_KEY:-}" ]; then
            echo "Found both aws credentials secret with both aws_access_key_id and aws_secret_access_key. Assuming S3 bucket"
            # This implements v4 auth https://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-auth-using-authorization-header.html
            path=$(echo "$url" | cut -d/ -f4-)
            echo "Bucket path is $path"
            date="$(date -u '+%Y%m%dT%H%M%SZ')"
            host=$(echo -n "$url" | awk -F '/' '{print $3}')
            if [[ "$host" == *.amazonaws.com ]] ; then
              # AWS Style
              region=$(echo -n "$host" | awk -F '.' '{print $3}')
            else
              # IBM Cloud style
              region=$(echo -n "$host" | awk -F '.' '{print $2}')
            fi

            # This e3b0c44 digest is digest of the empty string. No request body.
            payload_digest=e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855

            # Step 1: construct canonical request
            IFS= read -r -d '' canonical_request <<EOF || true
        $method
        /$path

        host:$host
        x-amz-content-sha256:$payload_digest
        x-amz-date:$date

        host;x-amz-content-sha256;x-amz-date
        $payload_digest
        EOF
            canonical_request=$(echo -n "$canonical_request" | head -c -1)  # Strip trailing newline
            canonical_digest=$(echo -n "$canonical_request" | sha256sum | cut -d " " -f 1)

            # Step 2: construct string to sign
            IFS= read -r -d '' string_to_sign <<EOF || true
        AWS4-HMAC-SHA256
        $date
        ${date%T*}/$region/s3/aws4_request
        $canonical_digest
        EOF
            string_to_sign=$(echo -n "$string_to_sign" | head -c -1)  # Strip trailing newline

            # Step 3: derive a signing key
            startkey="AWS4${AWS_SECRET_ACCESS_KEY}"
            datekey=$(echo -n "${date%T*}" | openssl dgst -sha256 -hex -hmac "${startkey}" | awk '{ print $2 }' | tr -d '\n')
            dateregionkey=$(echo -n "${region}" | openssl dgst -sha256 -hex -mac HMAC -macopt "hexkey:${datekey}" | awk '{ print $2 }' | tr -d '\n')
            dateregionservicekey=$(echo -n "s3" | openssl dgst -sha256 -hex -mac HMAC -macopt "hexkey:${dateregionkey}" | awk '{ print $2 }' | tr -d '\n')
            signingkey=$(echo -n "aws4_request" | openssl dgst -sha256 -hex -mac HMAC -macopt "hexkey:${dateregionservicekey}" | awk '{ print $2 }' | tr -d '\n')

            # Step 4: use the signing key
            signature=$(echo -n "$string_to_sign" | openssl dgst -sha256 -hex -mac HMAC -macopt "hexkey:${signingkey}" | awk '{ print $2 }' | tr -d '\n')
            authorization="AWS4-HMAC-SHA256 Credential=${AWS_ACCESS_KEY_ID}/${date%T*}/${region}/s3/aws4_request, SignedHeaders=host;x-amz-content-sha256;x-amz-date, Signature=${signature}"

            curl "${curl_args[@]}" \
                -H "X-Amz-Date: ${date}" \
                -H "X-Amz-Content-SHA256: $payload_digest" \
                -H "Authorization: ${authorization}" \
                --location "$url" \
                -o "$file"
          elif [ -n "${BEARER_TOKEN:-}" ]; then
            echo "Found bearer token. Using it for authentication."
            curl "${curl_args[@]}" -H "Authorization: Bearer ${BEARER_TOKEN}" --location "$url" -o "$file"
          else
            echo "Proceeding with anonymous requests"
            curl "${curl_args[@]}" --location "$url" -o "$file"
          fi
        }

        set -u

        echo "Selecting auth for $IMAGE"
        select-oci-auth $IMAGE > auth.json

        echo "Extracting artifact_type"
        ARTIFACT_TYPE=$(cat "$(pwd)/source/$OCI_COPY_FILE" | yq '.artifact_type')

        REPO=${IMAGE%:*}
        echo "Found that ${REPO} is the repository for ${IMAGE}"

        cat >artifact-manifest.json <<EOL
        {
          "schemaVersion": 2,
          "mediaType": "application/vnd.oci.image.manifest.v1+json",
          "artifactType": "${ARTIFACT_TYPE}",
          "config": {
            "mediaType": "application/vnd.oci.empty.v1+json",
            "digest": "sha256:44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
            "size": 2,
            "data": "e30="
          },
          "layers": [],
          "annotations": {
            "org.opencontainers.image.created": "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
          }
        }
        EOL

        echo "Ensuring that the empty blob exists, for the image manifest config."
        echo -n "{}" | oras blob push \
                --registry-config auth.json \
                ${REPO}@sha256:44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a \
                --media-type application/vnd.oci.empty.v1+json --size 2 -

        for varfile in "$(workspaces.source.path)"/vars/*; do
          echo "Reading $varfile"
          # shellcheck source=/dev/null
          source $varfile

          echo "Checking to see if blob $OCI_ARTIFACT_DIGEST exists"
          if [[ $(oras blob fetch --registry-config auth.json --descriptor "${REPO}@sha256:${OCI_ARTIFACT_DIGEST}") ]]; then
            echo "Blob for ${OCI_FILENAME} already exists in the registry at ${REPO}@sha256:${OCI_ARTIFACT_DIGEST}. Skipping download."
          else
            echo "Blob for ${OCI_FILENAME} does not yet exist in the registry at ${REPO}@sha256:${OCI_ARTIFACT_DIGEST}."
            echo "Downloading $OCI_SOURCE to $OCI_FILENAME"
            download "$OCI_SOURCE" "$OCI_FILENAME"

            echo "Confirming that digest of $OCI_FILENAME matches expected $OCI_ARTIFACT_DIGEST"
            echo "$OCI_ARTIFACT_DIGEST $OCI_FILENAME" | sha256sum --check

            echo "Pushing blob of $OCI_FILENAME of type $OCI_ARTIFACT_TYPE"
            oras blob push --registry-config auth.json ${REPO} --media-type ${OCI_ARTIFACT_TYPE} ${OCI_FILENAME}

            echo "Removing local copy of $OCI_FILENAME to save space."
            rm ${OCI_FILENAME}
          fi

          echo "Grabbing descriptor of blob from the registry"
          oras blob fetch --registry-config auth.json --descriptor "${REPO}@sha256:${OCI_ARTIFACT_DIGEST}" > descriptor.json

          echo "Setting mediaType to ${OCI_ARTIFACT_TYPE}"
          yq -oj -i '.mediaType = "'${OCI_ARTIFACT_TYPE}'"' descriptor.json

          echo "Inserting org.opencontainers.image.title = ${OCI_FILENAME} annotation"
          yq -oj -i '.annotations."org.opencontainers.image.title" = "'${OCI_FILENAME}'"' descriptor.json

          echo "Appending blob descriptor for ${OCI_FILENAME} to the overall artifact manifest for ${IMAGE}"
          yq -oj -i ".layers += $(cat descriptor.json)" artifact-manifest.json

          echo "Done with ${OCI_FILENAME}."
        done

        echo "Pushing complete artifact manifest to ${IMAGE}"
        oras manifest push --no-tty --registry-config auth.json "${IMAGE}" artifact-manifest.json

        RESULTING_DIGEST=$(oras resolve --registry-config auth.json "${IMAGE}")
        echo -n "$RESULTING_DIGEST" | tee "$(results.IMAGE_DIGEST.path)"
        echo -n "$IMAGE" | tee "$(results.IMAGE_URL.path)"
        echo -n "${IMAGE}@${RESULTING_DIGEST}" >"$(results.IMAGE_REF.path)"
      volumeMounts:
        - mountPath: /var/lib/containers
          name: varlibcontainers
      workingDir: $(workspaces.source.path)
    - name: sbom-generate
      image: quay.io/konflux-ci/sbom-utility-scripts@sha256:1939901046f2ec0afda6d48f32dc82f991d9a4e2b4b4513635b9c79e3d4c2872
      script: |
        #!/bin/bash
        set -euo pipefail

        IMAGE_URL=$(cat "$(results.IMAGE_URL.path)")
        IMAGE_DIGEST=$(cat "$(results.IMAGE_DIGEST.path)")
        oci_copy_file_path="$(pwd)/source/$OCI_COPY_FILE"

        python3 /scripts/sbom_for_oci_copy_task.py "$oci_copy_file_path" \
          --sbom-type "$SBOM_TYPE" \
          -o sbom.json

        python3 /scripts/add_image_reference.py \
          --image-url "$IMAGE_URL" \
          --image-digest "$IMAGE_DIGEST" \
          --input-file sbom.json \
          --output-file /tmp/sbom.tmp.json

        mv /tmp/sbom.tmp.json sbom.json
      workingDir: $(workspaces.source.path)
    - name: upload-sbom
      image: quay.io/konflux-ci/appstudio-utils:48c311af02858e2422d6229600e9959e496ddef1@sha256:91ddd999271f65d8ec8487b10f3dd378f81aa894e11b9af4d10639fd52bba7e8
      workingDir: $(workspaces.source.path)
      script: |
        cosign attach sbom --sbom sbom.json --type "$SBOM_TYPE" "$(cat "$(results.IMAGE_REF.path)")"
    - name: report-sbom-url
      image: quay.io/konflux-ci/yq:latest@sha256:93bb15cff64b708263055a5814b24a0b450d8724b86a7e5206396f25d81fcc21
      script: |
        #!/bin/bash
        REPO=${IMAGE%:*}
        echo "Found that ${REPO} is the repository for ${IMAGE}"
        SBOM_DIGEST=$(sha256sum sbom.json | awk '{ print $1 }')
        echo "Found that ${SBOM_DIGEST} is the SBOM digest"
        echo -n "${REPO}@sha256:${SBOM_DIGEST}" | tee $(results.SBOM_BLOB_URL.path)
      workingDir: $(workspaces.source.path)
  volumes:
    - emptyDir: {}
      name: varlibcontainers
  workspaces:
    - description: Workspace containing the source artifacts to copy
      name: source
