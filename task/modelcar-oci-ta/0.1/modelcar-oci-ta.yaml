apiVersion: tekton.dev/v1
kind: Task
metadata:
  annotations:
    tekton.dev/pipelines.minVersion: 0.12.1
    tekton.dev/tags: image-build, konflux
  labels:
    app.kubernetes.io/version: "0.1"
    build.appstudio.redhat.com/build_type: modelcar
  name: modelcar-oci-ta
spec:
  description: |-
    Given a base image and a OCI artifact reference with the model files, builds a ModelCar image.

    A ModelCar is a containerized approach to deploying machine learning models. It involves packaging
    model artifacts within a container image, enabling efficient and standardized deployment in
    Kubernetes environments, used as Sidecar containers (secondary containers that run alongside the
    main application container within the same Pod)

    The ModelCar image is built using the specified BASE_IMAGE parameter, which is extracted to an
    OCI image layout directory. Then all files included in the OCI artifact specified with the
    MODEL_IMAGE parameter are copied on top.

    An SBOM report defining the Model and Base Images as descendants of the ModelCar image is also
    generated in the process.
  params:
    - name: MODEL_IMAGE_AUTH
      description: Name of secret required to pull the model OCI artifact
      type: string
    - name: IMAGE
      description: Reference of the image we will push
      type: string
    - name: SBOM_TYPE
      description: 'Select the SBOM format to generate. Valid values: spdx,
        cyclonedx.'
      type: string
      default: spdx
    - name: SOURCE_ARTIFACT
      description: The Trusted Artifact URI pointing to the artifact with
        the application source code.
      type: string
    - name: BASE_IMAGE
      description: base image used to build the Modelcar image
      type: string
    - name: MODEL_IMAGE
      description: OCI artifact reference with the model files
      type: string
    - name: MODELCARD_PATH
      description: path to the Model Card
      type: string
    - name: REMOVE_ORIGINALS
      description: add --remove-originals param to olot
      type: string
      default: "false"
  results:
    - name: IMAGES
      description: Image reference of the built image containing both the repository and the digest
    - name: IMAGE_DIGEST
      description: Digest of the artifact just pushed
    - name: IMAGE_REF
      description: Image reference of the built image
    - name: IMAGE_URL
      description: Repository where the artifact was pushed
    - name: SBOM_BLOB_URL
      description: Link to the SBOM blob pushed to the registry.
  volumes:
    - name: varlibcontainers
      emptyDir: {}
    - name: workdir
      emptyDir: {}
    - name: model-secret
      secret:
        secretName: $(params.MODEL_IMAGE_AUTH)
    - name: trusted-ca
      configMap:
        items:
          - key: $(params.caTrustConfigMapKey)
            path: ca-bundle.crt
        name: $(params.caTrustConfigMapName)
        optional: true
  stepTemplate:
    env:
      - name: IMAGE
        value: $(params.IMAGE)
      - name: SBOM_TYPE
        value: $(params.SBOM_TYPE)
      - name: BASE_IMAGE
        value: $(params.BASE_IMAGE)
      - name: MODEL_IMAGE
        value: $(params.MODEL_IMAGE)
      - name: TARGET_OCI
        value: "/var/workdir/modelcar-oci"
    volumeMounts:
      - mountPath: /var/workdir
        name: workdir
  steps:
    - name: use-trusted-artifact
      image: quay.io/redhat-appstudio/build-trusted-artifacts:latest@sha256:9b180776a41d9a22a1c51539f1647c60defbbd55b44bbebdd4130e33512d8b0d
      args:
        - use
        - $(params.SOURCE_ARTIFACT)=/var/workdir/source
    - name: download-models-and-create-base
      image: quay.io/konflux-ci/release-service-utils:2f93b7ed6a2099e7187bb110a6b95caac3b8bdbc
      volumeMounts:
        - mountPath: /model-secret
          name: model-secret
      workingDir: /var/workdir
      script: |
        #!/bin/bash
        set -eu
        set -o pipefail

        if ! oras pull "$MODEL_IMAGE" \
          --registry-config /model-secret/.dockerconfigjson --output /var/workdir/models
        then
          echo "Failed to pull ${MODEL_IMAGE} from registry"
          exit 1
        fi
        chmod -R g+wx models

        oras copy --to-oci-layout "$BASE_IMAGE" "${TARGET_OCI}:latest"
        chmod -R g+w "$TARGET_OCI"

    - name: copy-model-files
      image: registry.access.redhat.com/ubi9/python-311:9.6-1753713955
      workingDir: /var/workdir
      env:
        - name: OLOT_VERSION
          value: 0.1.7
        - name: MODELCARD_PATH
          value: $(params.MODELCARD_PATH)
        - name: REMOVE_ORIGINALS
          value: $(params.REMOVE_ORIGINALS)
      script: |
        #!/bin/bash
        set -eu
        set -o pipefail

        REMOVE_ORIGINALS_ARG=""
        if [[ "$REMOVE_ORIGINALS" == "true" ]]; then
          REMOVE_ORIGINALS_ARG="--remove-originals"
        fi
        pip install olot=="${OLOT_VERSION}"
        olot "$REMOVE_ORIGINALS_ARG" -m "$MODELCARD_PATH" "$TARGET_OCI" models/*

    - name: push-and-write-results
      image: quay.io/konflux-ci/oras:latest@sha256:16d77d29cbdfdb7d77272c9c0c8b8c7f2d397c5e6381363b8d01766aa8bb518f
      workingDir: /var/workdir
      script: |
        #!/bin/bash
        set -eu
        set -o pipefail

        select-oci-auth "$IMAGE" >auth.json

        echo "Pushing complete artifact manifest to ${IMAGE}"
        if ! retry oras cp --to-registry-config auth.json --from-oci-layout "${TARGET_OCI}:latest" "$IMAGE"
        then
            echo "Failed to push complete artifact manifest to ${IMAGE}"
            exit 1
        fi
        echo "Push complete!"

        if ! RESULTING_DIGEST=$(retry oras resolve --registry-config auth.json "${IMAGE}")
        then
          echo "Failed to get digest for ${IMAGE} from registry"
          exit 1
        fi
        
        
        # Write main results IMMEDIATELY (following build-image-manifest pattern)
        echo -n "$RESULTING_DIGEST" > "$(results.IMAGE_DIGEST.path)"
        echo -n "$IMAGE" > "$(results.IMAGE_URL.path)"
        echo -n "${IMAGE}@${RESULTING_DIGEST}" > "$(results.IMAGE_REF.path)"
        
        # Extract digest list from oras for multiarch IMAGES result
        DIGESTS=$(oras manifest fetch \
          --registry-config auth.json \
          --format go-template \
          --template '{{range .content.manifests}}{{.digest}},{{end}}' \
          "$IMAGE")

        # Remove trailing comma
        DIGESTS="${DIGESTS%,}"

        # Compose full image references
        IMAGES=""
        IFS=',' read -ra DIGEST_ARR <<<"$DIGESTS"
        for DIGEST in "${DIGEST_ARR[@]}"; do
          IMAGES+="${IMAGE}@${DIGEST}, "
        done

        # Trim trailing comma and space
        IMAGES="${IMAGES%, }"
        
        echo -n "$IMAGES" > "$(results.IMAGES.path)"

        # Save manifest data for oci-index SBOM generation
        oras manifest fetch --registry-config auth.json "$IMAGE" > manifest_data.json
        
        # Create architecture mapping using oras templates and awk
        echo "Creating architecture mapping for multiarch SBOM generation..."
        echo "BASE_IMAGE: $BASE_IMAGE"
        
        # Parse base image manifests using awk for reliable text processing
        echo "Parsing base image manifests with awk..."
        
        # Extract base repo without tag/digest
        base_repo="$(echo "$BASE_IMAGE" | cut -d@ -f1 | cut -d: -f1)"
        
        # Get arch:digest pairs with fallback template paths
        echo "Trying .content.manifests template path for base image..."
        base_arch_digests=$(oras manifest fetch \
          --format go-template \
          --template '{{range .content.manifests}}{{.platform.architecture}}:{{.digest}} {{end}}' \
          "$BASE_IMAGE" 2>/dev/null)
          
        if [[ -z "$base_arch_digests" ]]; then
          echo "No results from .content.manifests, trying .manifests..."
          base_arch_digests=$(oras manifest fetch \
            --format go-template \
            --template '{{range .manifests}}{{.platform.architecture}}:{{.digest}} {{end}}' \
            "$BASE_IMAGE" 2>/dev/null)
        fi
        
        if [[ -z "$base_arch_digests" ]]; then
          echo "ERROR: Could not extract arch:digest pairs from BASE_IMAGE manifest"
          echo "This may not be a multiarch image or manifest structure is unexpected"
          exit 1
        fi
        
        echo "Base arch:digest pairs: '$base_arch_digests'"
        
        # Create base images mapping file using awk with detailed logging
        echo "$base_arch_digests" | awk -v base_repo="$base_repo" '
        BEGIN {
          print "=== AWK: Processing base image arch:digest pairs ===" > "/dev/stderr"
          processed = 0
        }
        {
          print "AWK: Processing line with " NF " fields: " $0 > "/dev/stderr"
          for (i = 1; i <= NF; i++) {
            print "AWK: Field " i ": " $i > "/dev/stderr"
            split_count = split($i, parts, ":")
            print "AWK: Split into " split_count " parts" > "/dev/stderr"
            
            if (split_count >= 3) {
              arch = parts[1]
              digest = parts[2] ":" parts[3]
              print "AWK: Parsed arch='" arch "', digest='" digest "'" > "/dev/stderr"
              
              if (arch != "" && arch != "<no" && digest != "" && digest != ":") {
                output_line = arch "|" base_repo "@" digest
                print output_line
                print "âœ“ Base image for " arch ": " base_repo "@" digest > "/dev/stderr"
                processed++
              } else {
                print "AWK: Skipped due to invalid arch/digest" > "/dev/stderr"
              }
            } else {
              print "AWK: Skipped field - insufficient parts (" split_count ")" > "/dev/stderr"
            }
          }
        }
        END {
          print "AWK: Processed " processed " base images" > "/dev/stderr"
        }' > base_images.txt
        
        echo "Base images mapping created:"
        cat base_images.txt
        
        # Parse built image manifests using awk  
        echo "Processing built image manifests with awk..."
        built_repo="$(echo "$IMAGE" | cut -d@ -f1 | cut -d: -f1)"
        
        # Get built image arch:digest pairs with fallback
        echo "Trying .content.manifests template path for built image..."
        built_arch_digests=$(oras manifest fetch --registry-config auth.json \
          --format go-template \
          --template '{{range .content.manifests}}{{.platform.architecture}}:{{.digest}} {{end}}' \
          "$IMAGE" 2>/dev/null)
          
        if [[ -z "$built_arch_digests" ]]; then
          echo "No results from .content.manifests, trying .manifests..."
          built_arch_digests=$(oras manifest fetch --registry-config auth.json \
            --format go-template \
            --template '{{range .manifests}}{{.platform.architecture}}:{{.digest}} {{end}}' \
            "$IMAGE" 2>/dev/null)
        fi
        
        if [[ -z "$built_arch_digests" ]]; then
          echo "ERROR: Could not extract arch:digest pairs from built IMAGE manifest"
          echo "This may not be a multiarch image or manifest structure is unexpected"
          exit 1
        fi
        
        echo "Built arch:digest pairs: '$built_arch_digests'"
        
        # Create built images mapping and join with base images using awk
        echo "$built_arch_digests" | awk -v built_repo="$built_repo" -v base_image="$BASE_IMAGE" '
        BEGIN {
          print "=== AWK: Loading base images mapping ===" > "/dev/stderr"
          base_count = 0
          
          # Load base images mapping
          while ((getline line < "base_images.txt") > 0) {
            if (split(line, parts, "|") >= 2) {
              base_images[parts[1]] = parts[2]
              print "AWK: Loaded base mapping: " parts[1] " -> " parts[2] > "/dev/stderr"
              base_count++
            }
          }
          close("base_images.txt")
          print "AWK: Loaded " base_count " base image mappings" > "/dev/stderr"
          
          print "=== AWK: Processing built image arch:digest pairs ===" > "/dev/stderr"
          arch_count = 0
        }
        {
          print "AWK: Processing built line with " NF " fields: " $0 > "/dev/stderr"
          for (i = 1; i <= NF; i++) {
            print "AWK: Built field " i ": " $i > "/dev/stderr"
            split_count = split($i, parts, ":")
            print "AWK: Split into " split_count " parts" > "/dev/stderr"
            
            if (split_count >= 3) {
              arch = parts[1]
              digest = parts[2] ":" parts[3]
              print "AWK: Parsed built arch='" arch "', digest='" digest "'" > "/dev/stderr"
              
              if (arch != "" && arch != "<no" && digest != "" && digest != ":") {
                built_image = built_repo "@" digest
                
                if (arch in base_images) {
                  final_base = base_images[arch]
                  print "AWK: Found matching base image for " arch > "/dev/stderr"
                } else {
                  final_base = base_image
                  print "AWK: No specific base image for " arch ", using default" > "/dev/stderr"
                }
                
                output_line = arch "|" built_image "|" final_base
                print output_line
                print "âœ“ " arch ": " built_image " (base: " final_base ")" > "/dev/stderr"
                arch_count++
              } else {
                print "AWK: Skipped due to invalid built arch/digest" > "/dev/stderr"
              }
            } else {
              print "AWK: Skipped built field - insufficient parts (" split_count ")" > "/dev/stderr"
            }
          }
        }
        END {
          print "AWK: Architecture mapping created for " arch_count " architectures" > "/dev/stderr"
        }' > arch_mapping.txt
        
        echo "Final architecture mapping created:"
        cat arch_mapping.txt
        
        # Get arch count for validation
        arch_count=$(wc -l < arch_mapping.txt)
        
        echo "=== VALIDATION CHECKS ==="
        echo "Base images file:"
        if [ -f "base_images.txt" ]; then
          echo "  Lines: $(wc -l < base_images.txt)"
          echo "  Content preview: $(head -2 base_images.txt)"
        else
          echo "  ERROR: base_images.txt not found!"
        fi
        
        echo "Architecture mapping file:"
        if [ -f "arch_mapping.txt" ]; then
          echo "  Lines: $(wc -l < arch_mapping.txt)"
          echo "  Content preview: $(head -2 arch_mapping.txt)"
        else
          echo "  ERROR: arch_mapping.txt not found!"
        fi
        
        if [ $arch_count -eq 0 ]; then
          echo "ERROR: No architectures found in final mapping!"
          echo "This may not be a multiarch image or template parsing failed"
          exit 1
        fi
        
        echo "âœ“ Architecture mapping completed successfully"

    - name: generate-sbom
      image: quay.io/konflux-ci/mobster@sha256:5af1aa13f97ff2006e33b1e5d422c3a0b178ae000b35c9309f952b5fb4c174ff
      workingDir: /var/workdir
      script: |
        #!/bin/bash
        set -e

        echo "=== GENERATE DUAL SBOM ==="
        
        MODELCAR_IMAGE=$(cat "$(results.IMAGE_REF.path)")
        IMAGE_DIGEST=$(cat "$(results.IMAGE_DIGEST.path)")
        IMAGE_URL=$(cat "$(results.IMAGE_URL.path)")
        
        echo "MODELCAR_IMAGE: $MODELCAR_IMAGE"
        echo "BASE_IMAGE: $BASE_IMAGE"
        echo "MODEL_IMAGE: $MODEL_IMAGE"

        # Validate tools and files before starting
        echo "=== ENVIRONMENT VALIDATION ==="
        echo "Checking required tools:"
        which awk || echo "WARNING: awk not found in PATH"
        which mobster || echo "ERROR: mobster not found in PATH"
        
        echo "Checking input files:"
        if [ ! -f "arch_mapping.txt" ]; then
          echo "ERROR: arch_mapping.txt not found!"
          echo "Files in workdir:"
          ls -la /var/workdir/
          exit 1
        fi
        echo "  arch_mapping.txt: $(wc -l < arch_mapping.txt) lines"
        
        echo "Generating ModelCar SBOMs for each architecture using correct base images..."
        
        # Process architecture mapping using awk for reliable parsing
        echo "Processing architecture mapping with awk..."
        
        # Initialize result files
        > sbom_files_list.txt
        > arch_images_list.txt
        
        # Use awk to process each line and generate SBOMs with detailed logging
        sbom_count=$(awk -F'|' -v model_image="$MODEL_IMAGE" -v sbom_type="$SBOM_TYPE" '
        BEGIN {
          print "=== AWK: Starting SBOM generation ===" > "/dev/stderr"
          success_count = 0
          total_lines = 0
        }
        {
          total_lines++
          print "AWK: Processing line " total_lines ": " $0 > "/dev/stderr"
          print "AWK: NF=" NF ", Field1='" $1 "', Field2='" $2 "', Field3='" $3 "'" > "/dev/stderr"
          
          if (NF >= 3 && $1 != "") {
            arch = $1
            built_image = $2
            base_image = $3
            sbom_file = "modelcar-" arch ".sbom.json"
            
            print "=== Generating ModelCar SBOM for " arch " ===" > "/dev/stderr"
            print "  Built image: " built_image > "/dev/stderr"
            print "  Base image: " base_image > "/dev/stderr"
            print "  Model image: " model_image > "/dev/stderr"
            print "  SBOM file: " sbom_file > "/dev/stderr"
            
            # Generate SBOM using mobster - add quotes for safety
            cmd = "mobster generate --output \"" sbom_file "\" modelcar --modelcar-image \"" built_image "\" --base-image \"" base_image "\" --model-image \"" model_image "\" --sbom-type \"" sbom_type "\""
            print "AWK: Executing command: " cmd > "/dev/stderr"
            
            exit_code = system(cmd)
            print "AWK: Command exit code: " exit_code > "/dev/stderr"
            
            if (exit_code == 0) {
              print "âœ“ ModelCar SBOM generated for " arch ": " sbom_file > "/dev/stderr"
              print sbom_file >> "sbom_files_list.txt"
              print built_image >> "arch_images_list.txt"
              success_count++
            } else {
              print "âœ— Failed to generate SBOM for " arch " (exit code: " exit_code ")" > "/dev/stderr"
            }
          } else {
            print "AWK: Skipped line - insufficient fields or empty arch" > "/dev/stderr"
          }
        }
        END {
          print "AWK: Processed " total_lines " lines, " success_count " successful SBOMs" > "/dev/stderr"
          print success_count
        }' arch_mapping.txt)
        
        echo "Generated $sbom_count ModelCar SBOMs"
        
        echo "=== FINAL VALIDATION ==="
        echo "SBOM files list:"
        if [ -f "sbom_files_list.txt" ]; then
          echo "  Lines: $(wc -l < sbom_files_list.txt)"
          echo "  Files: $(cat sbom_files_list.txt | tr '\n' ' ')"
        else
          echo "  ERROR: sbom_files_list.txt not found!"
        fi
        
        echo "Architecture images list:"
        if [ -f "arch_images_list.txt" ]; then
          echo "  Lines: $(wc -l < arch_images_list.txt)"
          echo "  Images: $(head -2 arch_images_list.txt | tr '\n' ' ')..."
        else
          echo "  ERROR: arch_images_list.txt not found!"
        fi
        
        echo "Generated SBOM files on disk:"
        ls -la *.sbom.json || echo "  No SBOM files found!"
        
        if [ $sbom_count -eq 0 ]; then
          echo "ERROR: No ModelCar SBOMs were generated successfully"
          exit 1
        fi

        # Generate OCI Index SBOM (for multiarch base image information)  
        if [ -f "manifest_data.json" ]; then
          echo "Generating OCI Index SBOM for multiarch..."
          mobster generate \
            --output oci-index.sbom.json \
            oci-index \
            --index-image-pullspec "$IMAGE_URL" \
            --index-image-digest "$IMAGE_DIGEST" \
            --index-manifest-path "manifest_data.json"
          echo "âœ“ OCI Index SBOM generated"
        else
          echo "Warning: No manifest data found, skipping OCI Index SBOM"
        fi

        # Set primary SBOM for backward compatibility (first arch-specific SBOM)
        if [ -f "sbom_files_list.txt" ] && [ -s "sbom_files_list.txt" ]; then
          PRIMARY_SBOM=$(head -n 1 sbom_files_list.txt)
          if [ -f "$PRIMARY_SBOM" ]; then
            cp "$PRIMARY_SBOM" sbom.json
            echo "Primary SBOM: $PRIMARY_SBOM"
          fi
        fi
        
        echo "âœ“ SBOM generation completed"
        

    - name: upload-sbom
      image: quay.io/konflux-ci/appstudio-utils:1610c1fc4cfc9c9053dbefc1146904a4df6659ef@sha256:90ac97b811073cb99a23232c15a08082b586c702b85da6200cf54ef505e3c50c
      workingDir: /var/workdir
      script: |
        #!/bin/bash
        set -e

        echo "=== UPLOAD SBOM ==="
        
        IMAGE_REF=$(cat "$(results.IMAGE_REF.path)")
        IMAGE_URL=$(cat "$(results.IMAGE_URL.path)")
        
        echo "IMAGE_REF: $IMAGE_REF"
        echo "IMAGE_URL: $IMAGE_URL"
        
        # Pre-select the correct credentials to work around cosign not supporting the containers-auth.json spec
        mkdir -p /tmp/auth && select-oci-auth "$IMAGE_REF" > /tmp/auth/config.json
        export DOCKER_CONFIG=/tmp/auth

        echo "Uploading SBOMs for all architectures..."
        UPLOADED_SBOMS=()
        
        # Upload ModelCar SBOM for each architecture-specific image
        if [ -f "sbom_files_list.txt" ] && [ -f "arch_images_list.txt" ]; then
          readarray -t SBOM_FILES < sbom_files_list.txt
          readarray -t ARCH_IMAGES < arch_images_list.txt
          
          echo "Found ${#SBOM_FILES[@]} SBOM files and ${#ARCH_IMAGES[@]} arch images"
          echo "=== DEBUGGING ARCH UPLOADS ==="
          echo "SBOM files: $(cat sbom_files_list.txt | tr '\n' ' ')"
          echo "Arch images: $(cat arch_images_list.txt | tr '\n' ' ')"
          
          for i in "${!SBOM_FILES[@]}"; do
            if [ $i -lt ${#ARCH_IMAGES[@]} ]; then
              SBOM_FILE="${SBOM_FILES[$i]}"
              ARCH_IMAGE="${ARCH_IMAGES[$i]}"
              
              echo "=== Upload $((i+1))/${#SBOM_FILES[@]} ==="
              echo "SBOM file: $SBOM_FILE"
              echo "Target image: $ARCH_IMAGE"
              echo "SBOM size: $(ls -lh "$SBOM_FILE" 2>/dev/null | awk '{print $5}' || echo 'file not found')"
              
              if retry cosign attach sbom --sbom "$SBOM_FILE" --type "$SBOM_TYPE" "$ARCH_IMAGE"; then
                echo "âœ“ $SBOM_FILE uploaded successfully to $ARCH_IMAGE"
                UPLOADED_SBOMS+=("$SBOM_FILE")
              else
                echo "âœ— Failed to upload $SBOM_FILE to $ARCH_IMAGE"
              fi
            fi
          done
        else
          echo "Warning: SBOM files list or arch images list not found"
        fi

        # Upload OCI Index SBOM to main image reference (digest-only format)
        if [ -f "oci-index.sbom.json" ]; then
          # Remove tag from IMAGE_URL and construct proper digest reference
          IMAGE_REPO="${IMAGE_URL%:*}"  # Remove everything after the last colon (the tag)
          MAIN_IMAGE_DIGEST="${IMAGE_REPO}@$(cat "$(results.IMAGE_DIGEST.path)")"
          echo "Uploading OCI Index SBOM to main image $MAIN_IMAGE_DIGEST..."
          if retry cosign attach sbom --sbom oci-index.sbom.json --type "$SBOM_TYPE" "$MAIN_IMAGE_DIGEST"; then
              echo "âœ“ OCI Index SBOM uploaded successfully"
              UPLOADED_SBOMS+=("oci-index.sbom.json")
          else
              echo "Warning: Failed to upload OCI Index SBOM, continuing..."
          fi
        fi

        # Calculate SBOM URL (from primary SBOM - first uploaded)
        if [ ${#UPLOADED_SBOMS[@]} -gt 0 ]; then
          PRIMARY_SBOM="${UPLOADED_SBOMS[0]}"
          sbom_repo="${IMAGE_URL%:*}"
          sbom_digest="$(sha256sum "$PRIMARY_SBOM" | cut -d' ' -f1)"
          SBOM_BLOB_URL="${sbom_repo}@sha256:${sbom_digest}"
        else
          echo "Warning: No SBOMs uploaded successfully"
          SBOM_BLOB_URL=""
        fi
        echo "SBOM_BLOB_URL: $SBOM_BLOB_URL"
        echo -n "$SBOM_BLOB_URL" > "$(results.SBOM_BLOB_URL.path)"
        
        echo "âœ“ SBOM upload completed"
