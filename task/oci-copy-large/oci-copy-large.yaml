apiVersion: tekton.dev/v1
kind: Task
metadata:
  annotations:
    tekton.dev/pipelines.minVersion: 0.12.1
    tekton.dev/tags: image-build, konflux
  labels:
    app.kubernetes.io/version: "0.3"
    build.appstudio.redhat.com/build_type: oci-copy-large
  name: oci-copy-large
spec:
  description: Given a file in the user's source directory, copy content from arbitrary urls into the OCI registry.
  params:
    - description: Reference of the image we will push
      name: IMAGE
      type: string
    - default: ./oci-copy-large.yaml
      description: Path to the oci copy file.
      name: OCI_COPY_FILE
      type: string
    - name: BEARER_TOKEN_SECRET_NAME
      description: >-
        Name of a secret which will be made available to the build as an Authorization header. Note, the token will
        be sent to all servers found in the oci-copy-large.yaml file. If you do not wish to send the token to all servers,
        different taskruns and therefore different oci artifacts must be used.
      type: string
      default: "does-not-exist"
    - name: AWS_SECRET_NAME
      description: >-
        Name of a secret which will be made available to the build to construct Authorization headers for requests to
        Amazon S3 using v2 auth https://docs.aws.amazon.com/AmazonS3/latest/userguide/RESTAuthentication.html.
        If specified, this will take precedence over BEARER_TOKEN_SECRET_NAME. The secret must contain two keys:
        `aws_access_key_id` and `aws_secret_access_key`. In the future, this will be reimplemented to use v4 auth:
        https://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-auth-using-authorization-header.html.
      type: string
      default: "does-not-exist"
    - name: SBOM_TYPE
      description: "Select the SBOM format to generate. Valid values: spdx, cyclonedx."
      type: string
      default: spdx

  results:
    - description: Digest of the artifact just pushed
      name: IMAGE_DIGEST
    - description: Repository where the artifact was pushed
      name: IMAGE_URL
    - description: Link to the SBOM blob pushed to the registry.
      name: SBOM_BLOB_URL
    - name: IMAGE_REF
      description: Image reference of the built image
  stepTemplate:
    env:
      - name: OCI_COPY_FILE
        value: $(params.OCI_COPY_FILE)
      - name: IMAGE
        value: $(params.IMAGE)
      - name: SBOM_TYPE
        value: $(params.SBOM_TYPE)
  steps:
    - name: prepare
      image: quay.io/konflux-ci/yq:latest@sha256:5ec48a4b1e7489e74547113688a36517fa1cce0d90fd26055b08b970cfafbacc
      script: |
        #!/bin/bash
        set -eu
        set -o pipefail

        oci_copy_file_path="$(pwd)/source/$OCI_COPY_FILE"

        mkdir -p "$(workspaces.source.path)/vars/"

        for entry in $(cat $oci_copy_file_path | yq '.artifacts[] | @json | @base64'); do
          entry=$(echo $entry | base64 -d)
          source=$(echo $entry | yq .source)
          filename=$(echo $entry | yq .filename)
          artifact_type=$(echo $entry | yq .type)
          artifact_digest=$(echo $entry | yq .sha256sum)
          varfile="${filename//\//-}"

          {
            echo "declare OCI_SOURCE=${source}";
            echo "declare OCI_FILENAME=${filename}";
            echo "declare OCI_ARTIFACT_TYPE=${artifact_type}";
            echo "declare OCI_ARTIFACT_DIGEST=${artifact_digest}";
          } > "$(workspaces.source.path)/vars/$varfile"

          echo "Wrote $(workspaces.source.path)/vars/$varfile with contents:"
          cat "$(workspaces.source.path)/vars/$varfile"
        done
      workingDir: $(workspaces.source.path)
    - name: oci-copy-large
      image: quay.io/konflux-ci/oras:latest@sha256:4542f5a2a046ca36653749a8985e46744a5d2d36ee10ca14409be718ce15129e
      computeResources:
        limits:
          memory: 4Gi
        requests:
          cpu: "2"
          memory: 2Gi
      securityContext:
        capabilities:
          add:
            - SETFCAP
      env:
      - name: BEARER_TOKEN
        valueFrom:
          secretKeyRef:
            name: $(params.BEARER_TOKEN_SECRET_NAME)
            key: token
            optional: true
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: $(params.AWS_SECRET_NAME)
            key: aws_access_key_id
            optional: true
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: $(params.AWS_SECRET_NAME)
            key: aws_secret_access_key
            optional: true
      script: |
        #!/bin/bash
        set -e
        set -o pipefail

        download() {
          url="$1"
          file="$2"

          directory=$(dirname "${file}")
          echo "Found directory of ${file} to be ${directory}"
          if [ ! -d "${directory}" ]; then
            echo "Found that directory ${directory} does not exist. Creating."
            mkdir -p "${directory}"
          fi

          curl_args=(--fail --silent --show-error)
          if [ -n "${AWS_ACCESS_KEY_ID:-}" ] && [ -n "${AWS_SECRET_ACCESS_KEY:-}" ]; then
            echo "Found both aws credentials secret with both aws_access_key_id and aws_secret_access_key. Assuming S3 bucket"
            # Configure AWS CLI for parallel multipart downloads
            mkdir -p ~/.aws
            cat > ~/.aws/config <<EOF
        [default]
        s3 =
          max_concurrent_requests = 50
          multipart_threshold = 64MB
          multipart_chunksize = 16MB
        EOF
            # Extract bucket and path from URL for aws s3 cp
            host=$(echo -n "$url" | awk -F '/' '{print $3}')
            path=$(echo "$url" | cut -d/ -f4-)

            if [[ "$host" == *.s3.*.amazonaws.com ]]; then
              # AWS virtual-hosted-style: bucket.s3.region.amazonaws.com/key
              bucket=$(echo "$host" | cut -d. -f1)
              region=$(echo "$host" | cut -d. -f3)
              s3_uri="s3://${bucket}/${path}"
            elif [[ "$host" == s3.*.amazonaws.com ]]; then
              # AWS path-style: s3.region.amazonaws.com/bucket/key
              region=$(echo "$host" | cut -d. -f2)
              bucket=$(echo "$path" | cut -d/ -f1)
              key=$(echo "$path" | cut -d/ -f2-)
              s3_uri="s3://${bucket}/${key}"
            elif [[ "$host" == *.s3.*.cloud-object-storage.appdomain.cloud ]]; then
              # IBM Cloud COS virtual-hosted: bucket.s3.region.cloud-object-storage.appdomain.cloud/key
              bucket=$(echo "$host" | cut -d. -f1)
              region=$(echo "$host" | cut -d. -f3)
              s3_uri="s3://${bucket}/${path}"
              export AWS_ENDPOINT_URL="https://s3.${region}.cloud-object-storage.appdomain.cloud"
            elif [[ "$host" == s3.*.cloud-object-storage.appdomain.cloud ]]; then
              # IBM Cloud COS path-style: s3.region.cloud-object-storage.appdomain.cloud/bucket/key
              region=$(echo "$host" | cut -d. -f2)
              bucket=$(echo "$path" | cut -d/ -f1)
              key=$(echo "$path" | cut -d/ -f2-)
              s3_uri="s3://${bucket}/${key}"
              export AWS_ENDPOINT_URL="https://${host}"
            else
              # Generic S3-compatible storage: host/bucket/key
              bucket=$(echo "$path" | cut -d/ -f1)
              key=$(echo "$path" | cut -d/ -f2-)
              s3_uri="s3://${bucket}/${key}"
              export AWS_ENDPOINT_URL="https://${host}"
            fi

            echo "Downloading from S3 using AWS CLI with parallel multipart transfers"
            echo "S3 URI: ${s3_uri}"
            aws s3 cp "${s3_uri}" "${file}"
          elif [ -n "${BEARER_TOKEN:-}" ]; then
            echo "Found bearer token. Using it for authentication."
            curl "${curl_args[@]}" -H "Authorization: Bearer ${BEARER_TOKEN}" --location "$url" -o "$file"
          else
            echo "Proceeding with anonymous requests"
            curl "${curl_args[@]}" --location "$url" -o "$file"
          fi
        }

        set -u

        echo "Selecting auth for $IMAGE"
        select-oci-auth $IMAGE > auth.json

        echo "Extracting artifact_type"
        ARTIFACT_TYPE=$(cat "$(pwd)/source/$OCI_COPY_FILE" | yq '.artifact_type')

        REPO=${IMAGE%:*}
        echo "Found that ${REPO} is the repository for ${IMAGE}"

        cat >artifact-manifest.json <<EOL
        {
          "schemaVersion": 2,
          "mediaType": "application/vnd.oci.image.manifest.v1+json",
          "artifactType": "${ARTIFACT_TYPE}",
          "config": {
            "mediaType": "application/vnd.oci.empty.v1+json",
            "digest": "sha256:44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
            "size": 2,
            "data": "e30="
          },
          "layers": [],
          "annotations": {
            "org.opencontainers.image.created": "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
          }
        }
        EOL

        echo "Ensuring that the empty blob exists, for the image manifest config."
        if ! echo -n "{}" | retry oras blob push \
                --registry-config auth.json \
                ${REPO}@sha256:44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a \
                --media-type application/vnd.oci.empty.v1+json --size 2 -
        then
          echo "Failed to push empty blob to registry"
          exit 1
        fi

        for varfile in "$(workspaces.source.path)"/vars/*; do
          echo "Reading $varfile"
          # shellcheck source=/dev/null
          source $varfile

          echo "Checking to see if blob $OCI_ARTIFACT_DIGEST exists"
          if [[ $(oras blob fetch --registry-config auth.json --descriptor "${REPO}@sha256:${OCI_ARTIFACT_DIGEST}") ]]; then
            echo "Blob for ${OCI_FILENAME} already exists in the registry at ${REPO}@sha256:${OCI_ARTIFACT_DIGEST}. Skipping download."
          else
            echo "Blob for ${OCI_FILENAME} does not yet exist in the registry at ${REPO}@sha256:${OCI_ARTIFACT_DIGEST}."
            echo "Downloading $OCI_SOURCE to $OCI_FILENAME"
            download "$OCI_SOURCE" "$OCI_FILENAME"

            echo "Confirming that digest of $OCI_FILENAME matches expected $OCI_ARTIFACT_DIGEST"
            echo "$OCI_ARTIFACT_DIGEST $OCI_FILENAME" | sha256sum --check

            echo "Pushing blob of $OCI_FILENAME of type $OCI_ARTIFACT_TYPE"
            if ! retry oras blob push --registry-config auth.json "${REPO}" --media-type "${OCI_ARTIFACT_TYPE}" "${OCI_FILENAME}"
            then
              echo "Failed to push blob of $OCI_FILENAME to registry"
              exit 1
            fi

            echo "Removing local copy of $OCI_FILENAME to save space."
            rm ${OCI_FILENAME}
          fi

          echo "Grabbing descriptor of blob from the registry"
          if ! retry oras blob fetch --registry-config auth.json --descriptor "${REPO}@sha256:${OCI_ARTIFACT_DIGEST}" > descriptor.json
          then
            echo "Failed to fetch blob ${REPO}@sha256:${OCI_ARTIFACT_DIGEST} from registry"
            exit 1
          fi

          echo "Setting mediaType to ${OCI_ARTIFACT_TYPE}"
          yq -oj -i '.mediaType = "'${OCI_ARTIFACT_TYPE}'"' descriptor.json

          echo "Inserting org.opencontainers.image.title = ${OCI_FILENAME} annotation"
          yq -oj -i '.annotations."org.opencontainers.image.title" = "'${OCI_FILENAME}'"' descriptor.json

          echo "Appending blob descriptor for ${OCI_FILENAME} to the overall artifact manifest for ${IMAGE}"
          yq -oj -i ".layers += $(cat descriptor.json)" artifact-manifest.json

          echo "Done with ${OCI_FILENAME}."
        done

        echo "Pushing complete artifact manifest to ${IMAGE}"
        if ! retry oras manifest push --registry-config auth.json "${IMAGE}" artifact-manifest.json
        then
          echo "Failed to push complete artifact manifest to ${IMAGE}"
          exit 1
        fi

        if ! RESULTING_DIGEST=$(retry oras resolve --registry-config auth.json "${IMAGE}")
        then
          echo "Failed to get digest for ${IMAGE} from registry"
          exit 1
        fi
        echo -n "$RESULTING_DIGEST" | tee "$(results.IMAGE_DIGEST.path)"
        echo -n "$IMAGE" | tee "$(results.IMAGE_URL.path)"
        echo -n "${IMAGE}@${RESULTING_DIGEST}" >"$(results.IMAGE_REF.path)"
      volumeMounts:
        - mountPath: /var/lib/containers
          name: varlibcontainers
      workingDir: $(workspaces.source.path)
    - name: sbom-generate
      image: quay.io/konflux-ci/mobster:1.1.0-1762282332@sha256:17d208056137237e0c9619216a93c111b97a3d2214bf7ab7907856c344beac65
      script: |
        #!/bin/bash
        set -euo pipefail

        IMAGE_URL=$(cat "$(results.IMAGE_URL.path)")
        IMAGE_DIGEST=$(cat "$(results.IMAGE_DIGEST.path)")
        OCI_COPY_FILE_PATH="$(pwd)/source/$OCI_COPY_FILE"

        mobster generate \
          --output sbom.json \
          oci-artifact \
          --oci-copy-large-yaml "$OCI_COPY_FILE_PATH" \
          --image-pullspec "$IMAGE_URL" \
          --image-digest "$IMAGE_DIGEST" \
          --sbom-type "$SBOM_TYPE"

      workingDir: $(workspaces.source.path)
    - name: upload-sbom
      image: quay.io/konflux-ci/appstudio-utils:1610c1fc4cfc9c9053dbefc1146904a4df6659ef@sha256:90ac97b811073cb99a23232c15a08082b586c702b85da6200cf54ef505e3c50c
      workingDir: $(workspaces.source.path)
      script: |
        # Pre-select the correct credentials to work around cosign not supporting the containers-auth.json spec
        mkdir -p /tmp/auth && select-oci-auth "$(cat "$(results.IMAGE_REF.path)")" > /tmp/auth/config.json
        DOCKER_CONFIG=/tmp/auth cosign attach sbom --sbom sbom.json --type "$SBOM_TYPE" "$(cat "$(results.IMAGE_REF.path)")"
    - name: report-sbom-url
      image: quay.io/konflux-ci/yq:latest@sha256:5ec48a4b1e7489e74547113688a36517fa1cce0d90fd26055b08b970cfafbacc
      script: |
        #!/bin/bash
        REPO=${IMAGE%:*}
        echo "Found that ${REPO} is the repository for ${IMAGE}"
        SBOM_DIGEST=$(sha256sum sbom.json | awk '{ print $1 }')
        echo "Found that ${SBOM_DIGEST} is the SBOM digest"
        echo -n "${REPO}@sha256:${SBOM_DIGEST}" | tee $(results.SBOM_BLOB_URL.path)
      workingDir: $(workspaces.source.path)
  volumes:
    - emptyDir: {}
      name: varlibcontainers
  workspaces:
    - description: Workspace containing the source artifacts to copy
      name: source
